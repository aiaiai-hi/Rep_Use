# app.py
import streamlit as st
import streamlit.components.v1 as components
import pandas as pd
import numpy as np
from io import BytesIO

# –ü–æ–∏—Å–∫ –ø–æ –ø–æ–ª—è–º
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# –õ–∏–Ω–µ–π–Ω–æ—Å—Ç—å
from pyvis.network import Network
import plotly.graph_objects as go

st.set_page_config(page_title="DWH ‚Üí –ü–æ–¥–±–æ—Ä –ø–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º, –ø—Ä–æ—Ç–æ—Ç–∏–ø –∏ –ª–∏–Ω–µ–π–Ω–æ—Å—Ç—å", layout="wide")

# ============================ –£–¢–ò–õ–ò–¢–´ =========================================
def df_to_excel_bytes(df: pd.DataFrame, sheet_name="data") -> bytes:
    output = BytesIO()
    with pd.ExcelWriter(output, engine="openpyxl") as writer:
        df.to_excel(writer, index=False, sheet_name=sheet_name)
    return output.getvalue()

def download_button_for_df(df, label, filename):
    st.download_button(label=label, data=df_to_excel_bytes(df),
                       file_name=filename, mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

# ---------------- TF-IDF –ø–æ–∏—Å–∫–æ–≤—ã–π –∏–Ω–¥–µ–∫—Å ----------------
def build_search_text(row, datasets):
    ds = datasets[datasets.dataset_id == row["dataset_id"]].iloc[0]
    return " ".join([
        str(row.get("business_field_name","")),
        str(row.get("business_algorithm","")),
        str(row["column"]),
        " ".join(row.get("tags", [])) if isinstance(row.get("tags"), list) else str(row.get("tags","")),
        f"{row['schema']}.{row['table']}",
        str(ds["name"]),
        str(ds["system"])
    ])

def build_search_index(dataset_fields, datasets):
    df = dataset_fields.copy()
    df["search_text"] = df.apply(lambda r: build_search_text(r, datasets), axis=1)
    vectorizer = TfidfVectorizer(ngram_range=(1,2), analyzer="word", min_df=1)
    tfidf = vectorizer.fit_transform(df["search_text"].astype(str).values)
    return vectorizer, tfidf

def search_fields(query: str, dataset_fields, vectorizer, tfidf, top_k: int = 30):
    if not query.strip():
        return []
    q_vec = vectorizer.transform([query])
    sim = cosine_similarity(q_vec, tfidf).ravel()
    idx = np.argsort(sim)[::-1][:top_k]
    return [(dataset_fields.iloc[i]["ref"], float(sim[i])) for i in idx if sim[i] > 0]

# ---------------- –õ–∏–Ω–µ–π–Ω–æ—Å—Ç—å ----------------
def build_lineage_edges(dataset_fields: pd.DataFrame, report_fields: pd.DataFrame):
    """
    dataset(schema.table) -> field(schema.table.column) -> report(report:<id>)
    """
    df = dataset_fields.copy()
    df["dataset"] = df["schema"] + "." + df["table"]
    edges = []
    # dataset -> field
    for _, r in df.iterrows():
        ds = r["dataset"]
        field_ref = f"{r['schema']}.{r['table']}.{r['column']}"
        edges.append((ds, field_ref, "dataset‚Üífield"))
    # field -> report
    for _, r in report_fields.iterrows():
        field_ref = r["source_ref"]
        rep = f"report:{r['report_id']}"
        edges.append((field_ref, rep, "field‚Üíreport"))
    return edges

def pyvis_graph(edges, reports: pd.DataFrame, datasets: pd.DataFrame, height="650px"):
    g = Network(height=height, width="100%", bgcolor="#FFFFFF", font_color="#111111", notebook=False, directed=True)
    g.barnes_hut(gravity=-20000, central_gravity=0.1, spring_length=150, spring_strength=0.01)

    ds_set = set(datasets["name"].tolist())
    report_meta = {f"report:{r.report_id}": r.name for _, r in reports.iterrows()}

    def node_style(n):
        if n in ds_set:             # dataset
            return dict(color="#1f77b4", shape="box")
        if n.startswith("report:"): # report
            return dict(color="#2ca02c", shape="box")
        if n.count(".") == 2:       # field
            return dict(color="#ff7f0e", shape="ellipse")
        return dict(color="#7f7f7f", shape="dot")

    nodes = set()
    for s, t, lbl in edges:
        for n in (s, t):
            if n not in nodes:
                style = node_style(n)
                title = n
                if n in report_meta:
                    title = f"{n} | {report_meta[n]}"
                label = n.split(".")[-1] if n.count(".")>=1 else (report_meta.get(n,n))
                g.add_node(n, label=label, title=title, **style)
                nodes.add(n)
        g.add_edge(s, t, title=lbl, arrows="to")

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –≥—Ä–∞—Ñ–∞: –í–ê–ñ–ù–û ‚Äî —Å—Ç—Ä–æ–≥–æ JSON, –±–µ–∑ "var options ="
    g.set_options("""
    {
      "nodes": { "borderWidth": 1, "size": 18 },
      "edges": { "color": { "color": "#B3B3B3" }, "smooth": { "type": "dynamic" } },
      "physics": { "stabilization": true }
    }
    """)

    return g

def sankey_figure(edges):
    nodes = sorted(set([s for s,_,_ in edges] + [t for _,t,_ in edges]))
    idx = {n:i for i,n in enumerate(nodes)}
    source = [idx[s] for s,_,_ in edges]
    target = [idx[t] for _,t,_ in edges]
    value  = [1 for _ in edges]
    fig = go.Figure(data=[go.Sankey(
        node=dict(pad=15, thickness=20, line=dict(width=0.5), label=nodes),
        link=dict(source=source, target=target, value=value)
    )])
    fig.update_layout(height=650, margin=dict(l=10,r=10,t=10,b=10))
    return fig

def filter_edges_by_report(edges, report_id: int):
    rnode = f"report:{report_id}"
    keep = set([rnode])
    changed = True
    while changed:
        changed = False
        for s,t,_ in edges:
            if t in keep and s not in keep:
                keep.add(s); changed = True
    return [(s,t,l) for s,t,l in edges if s in keep and t in keep]

# ====================== –¢–ï–°–¢–û–í–´–ï –î–ê–ù–ù–´–ï (–º–æ–∂–Ω–æ –∑–∞–º–µ–Ω–∏—Ç—å) ======================
def load_default_frames():
    datasets = pd.DataFrame([
        {"dataset_id":10,"name":"dm.sales_facts","layer":"vitrine","owner":"DWH","sla_minutes":120,"pii_flags":"","quality_score":0.93,"granularity":"txn_day_sku","system":"DWH / Sales Mart"},
        {"dataset_id":11,"name":"dm.customer_facts","layer":"vitrine","owner":"DWH","sla_minutes":1440,"pii_flags":"PII","quality_score":0.88,"granularity":"customer_month","system":"DWH / CRM Mart"},
        {"dataset_id":12,"name":"raw.erp_costs","layer":"raw","owner":"DataOps","sla_minutes":60,"pii_flags":"","quality_score":0.76,"granularity":"sku_day","system":"ERP"},
        {"dataset_id":13,"name":"dm.finance_facts","layer":"vitrine","owner":"DWH","sla_minutes":1440,"pii_flags":"","quality_score":0.86,"granularity":"dept_month","system":"DWH / Finance Mart"},
        {"dataset_id":14,"name":"raw.crm_events","layer":"raw","owner":"MarTech","sla_minutes":30,"pii_flags":"PII","quality_score":0.71,"granularity":"event","system":"CRM"},
        {"dataset_id":15,"name":"dm.geo_dim","layer":"vitrine","owner":"DWH","sla_minutes":1440,"pii_flags":"","quality_score":0.95,"granularity":"region","system":"DWH / Master Data"},
        {"dataset_id":16,"name":"dm.sales_dim","layer":"vitrine","owner":"DWH","sla_minutes":1440,"pii_flags":"","quality_score":0.92,"granularity":"channel","system":"DWH / Master Data"},
        {"dataset_id":17,"name":"dm.customer_dim","layer":"vitrine","owner":"DWH","sla_minutes":1440,"pii_flags":"PII","quality_score":0.90,"granularity":"customer","system":"DWH / Master Data"},
    ])
    reports = pd.DataFrame([
        {"report_id":1,"name":"–ü—Ä–æ–¥–∞–∂–∏ –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º","owner":"BI Team","frequency":"–ï–∂–µ–¥–Ω–µ–≤–Ω–æ","business_domain":"Sales","is_automated":True,"automation_score":92,"description":"–í–æ—Ä–æ–Ω–∫–∞ –ø—Ä–æ–¥–∞–∂ –∏ –≤—ã—Ä—É—á–∫–∞ –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º –∏ –∫–∞–Ω–∞–ª–∞–º."},
        {"report_id":2,"name":"–ú–∞—Ä–∂–∏–Ω–∞–ª—å–Ω–æ—Å—Ç—å SKU (—Ä—É—á–Ω–æ–π)","owner":"Finance","frequency":"–ï–∂–µ–Ω–µ–¥–µ–ª—å–Ω–æ","business_domain":"Finance","is_automated":False,"automation_score":58,"description":"–†—É—á–Ω–æ–π excel –ø–æ –º–∞—Ä–∂–µ –∏ —Å–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç–∏ –Ω–∞ —É—Ä–æ–≤–Ω–µ SKU."},
        {"report_id":3,"name":"Churn –¥–∞—à–±–æ—Ä–¥","owner":"CRM","frequency":"–ï–∂–µ–º–µ—Å—è—á–Ω–æ","business_domain":"CRM","is_automated":True,"automation_score":81,"description":"–û—Ç—Ç–æ–∫ –∫–ª–∏–µ–Ω—Ç–æ–≤, —Ä–µ—Ç–µ–Ω—à–Ω –∏ —Å–µ–≥–º–µ–Ω—Ç—ã."},
        {"report_id":4,"name":"–ü–ª–∞–Ω/–§–∞–∫—Ç –î–æ—Ö–æ–¥–æ–≤","owner":"FP&A","frequency":"–ï–∂–µ–º–µ—Å—è—á–Ω–æ","business_domain":"Finance","is_automated":True,"automation_score":76,"description":"–°–≤–æ–¥ –¥–æ—Ö–æ–¥–æ–≤ –ø—Ä–æ—Ç–∏–≤ –±—é–¥–∂–µ—Ç–∞ –ø–æ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è–º."},
    ])
    report_fields = pd.DataFrame([
        {"report_id":1,"business_field_name":"–í—ã—Ä—É—á–∫–∞","business_algorithm":"SUM(price*qty) –ø–æ –¥–Ω—é/sku","source_ref":"dm.sales_facts.revenue","is_from_vitrine":True},
        {"report_id":1,"business_field_name":"–ö–∞–Ω–∞–ª –ø—Ä–æ–¥–∞–∂","business_algorithm":"–°–ø—Ä–∞–≤–æ—á–Ω–∏–∫ –∫–∞–Ω–∞–ª–æ–≤","source_ref":"dm.sales_dim.channel","is_from_vitrine":True},
        {"report_id":1,"business_field_name":"–†–µ–≥–∏–æ–Ω","business_algorithm":"–°–ø—Ä–∞–≤–æ—á–Ω–∏–∫ –≥–µ–æ–≥—Ä–∞—Ñ–∏–π","source_ref":"dm.geo_dim.region_name","is_from_vitrine":True},
        {"report_id":2,"business_field_name":"SKU","business_algorithm":"–ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Ç–æ–≤–∞—Ä–∞ (ERP)","source_ref":"raw.erp_costs.sku","is_from_vitrine":False},
        {"report_id":2,"business_field_name":"–°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å","business_algorithm":"–°—É–º–º–∞ –ø—Ä—è–º—ã—Ö –∑–∞—Ç—Ä–∞—Ç (ERP)","source_ref":"raw.erp_costs.cogs","is_from_vitrine":False},
        {"report_id":2,"business_field_name":"–¶–µ–Ω–∞ –ø—Ä–æ–¥–∞–∂–∏","business_algorithm":"–¶–µ–Ω–∞ –∏–∑ —Ñ–∞–∫—Ç–æ–≤ –ø—Ä–æ–¥–∞–∂","source_ref":"dm.sales_facts.price","is_from_vitrine":True},
        {"report_id":3,"business_field_name":"–ö–ª–∏–µ–Ω—Ç","business_algorithm":"–ö–ª—é—á –∫–ª–∏–µ–Ω—Ç–∞ (Master)","source_ref":"dm.customer_dim.customer_id","is_from_vitrine":True},
        {"report_id":3,"business_field_name":"–°—Ç–∞—Ç—É—Å –æ—Ç—Ç–æ–∫–∞","business_algorithm":"–§–ª–∞–≥ churn (–ª–æ–≥–∏–∫–∞ CRM)","source_ref":"dm.customer_facts.churn_flag","is_from_vitrine":True},
        {"report_id":3,"business_field_name":"–î–∞—Ç–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–π –ø–æ–∫—É–ø–∫–∏","business_algorithm":"Max(order_dt) –ø–æ –∫–ª–∏–µ–Ω—Ç—É","source_ref":"dm.customer_facts.last_purchase_dt","is_from_vitrine":True},
        {"report_id":4,"business_field_name":"–î–æ—Ö–æ–¥ —Ñ–∞–∫—Ç","business_algorithm":"–§–∞–∫—Ç –¥–æ—Ö–æ–¥–æ–≤ –∑–∞ –ø–µ—Ä–∏–æ–¥","source_ref":"dm.finance_facts.revenue_actual","is_from_vitrine":True},
        {"report_id":4,"business_field_name":"–î–æ—Ö–æ–¥ –ø–ª–∞–Ω","business_algorithm":"–ë—é–¥–∂–µ—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–æ—Ö–æ–¥–æ–≤","source_ref":"dm.finance_facts.revenue_budget","is_from_vitrine":True},
    ])
    dataset_fields = pd.DataFrame([
        {"dataset_id":10,"schema":"dm","table":"sales_facts","column":"revenue","dtype":"decimal","completeness":0.99,"uniqueness":0.95,"tags":["–≤—ã—Ä—É—á–∫–∞","–¥–æ—Ö–æ–¥","–æ–±–æ—Ä–æ—Ç","revenue","sales"],"business_field_name":"–í—ã—Ä—É—á–∫–∞","business_algorithm":"SUM(price*qty)"},
        {"dataset_id":10,"schema":"dm","table":"sales_facts","column":"price","dtype":"decimal","completeness":0.98,"uniqueness":0.92,"tags":["—Ü–µ–Ω–∞","price","—Å—Ç–æ–∏–º–æ—Å—Ç—å –ø—Ä–æ–¥–∞–∂–∏"],"business_field_name":"–¶–µ–Ω–∞ –ø—Ä–æ–¥–∞–∂–∏","business_algorithm":"price –ø–æ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏"},
        {"dataset_id":10,"schema":"dm","table":"sales_facts","column":"sku_id","dtype":"string","completeness":0.97,"uniqueness":0.80,"tags":["sku","—Ç–æ–≤–∞—Ä","–∞—Ä—Ç–∏–∫—É–ª"],"business_field_name":"SKU","business_algorithm":"–ö–ª—é—á SKU"},
        {"dataset_id":10,"schema":"dm","table":"sales_facts","column":"channel","dtype":"string","completeness":0.98,"uniqueness":0.70,"tags":["–∫–∞–Ω–∞–ª","–æ–Ω–ª–∞–π–Ω","–æ—Ñ—Ñ–ª–∞–π–Ω","—Ä–æ–∑–Ω–∏—Ü–∞","ecom"],"business_field_name":"–ö–∞–Ω–∞–ª –ø—Ä–æ–¥–∞–∂","business_algorithm":"–°–ø—Ä–∞–≤–æ—á–Ω–∏–∫ –∫–∞–Ω–∞–ª–æ–≤"},
        {"dataset_id":10,"schema":"dm","table":"sales_facts","column":"region_id","dtype":"int","completeness":0.98,"uniqueness":0.60,"tags":["—Ä–µ–≥–∏–æ–Ω","–≥–µ–æ","–æ–±–ª–∞—Å—Ç—å"],"business_field_name":"–†–µ–≥–∏–æ–Ω ID","business_algorithm":"–°—Å—ã–ª–∫–∞ –Ω–∞ geo_dim"},
        {"dataset_id":11,"schema":"dm","table":"customer_facts","column":"churn_flag","dtype":"bool","completeness":0.97,"uniqueness":1.00,"tags":["–æ—Ç—Ç–æ–∫","churn","—É—à—ë–ª","—É–¥–µ—Ä–∂–∞–Ω–∏–µ"],"business_field_name":"–°—Ç–∞—Ç—É—Å –æ—Ç—Ç–æ–∫–∞","business_algorithm":"ML/–ø—Ä–∞–≤–∏–ª–æ churn"},
        {"dataset_id":11,"schema":"dm","table":"customer_facts","column":"last_purchase_dt","dtype":"date","completeness":0.96,"uniqueness":0.90,"tags":["–ø–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–∫—É–ø–∫–∞","recency","lrp"],"business_field_name":"–î–∞—Ç–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–π –ø–æ–∫—É–ø–∫–∏","business_algorithm":"Max(order_dt)"},
        {"dataset_id":13,"schema":"dm","table":"finance_facts","column":"revenue_actual","dtype":"decimal","completeness":0.98,"uniqueness":0.95,"tags":["–¥–æ—Ö–æ–¥ —Ñ–∞–∫—Ç","—Ñ–∞–∫—Ç","actual","–≤—ã—Ä—É—á–∫–∞"],"business_field_name":"–î–æ—Ö–æ–¥ —Ñ–∞–∫—Ç","business_algorithm":"–§–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –¥–æ—Ö–æ–¥—ã"},
        {"dataset_id":13,"schema":"dm","table":"finance_facts","column":"revenue_budget","dtype":"decimal","completeness":0.98,"uniqueness":0.95,"tags":["–ø–ª–∞–Ω –¥–æ—Ö–æ–¥","–±—é–¥–∂–µ—Ç","budget"],"business_field_name":"–î–æ—Ö–æ–¥ –ø–ª–∞–Ω","business_algorithm":"–ë—é–¥–∂–µ—Ç –¥–æ—Ö–æ–¥–æ–≤"},
        {"dataset_id":15,"schema":"dm","table":"geo_dim","column":"region_name","dtype":"string","completeness":0.99,"uniqueness":0.95,"tags":["—Ä–µ–≥–∏–æ–Ω","–≥–µ–æ–≥—Ä–∞—Ñ–∏—è","—Ä–µ–≥–∏–æ–Ω –Ω–∞–∑–≤–∞–Ω–∏–µ"],"business_field_name":"–†–µ–≥–∏–æ–Ω","business_algorithm":"–°–ø—Ä–∞–≤–æ—á–Ω–∏–∫ –≥–µ–æ–≥—Ä–∞—Ñ–∏–π"},
        {"dataset_id":16,"schema":"dm","table":"sales_dim","column":"channel","dtype":"string","completeness":0.99,"uniqueness":0.95,"tags":["–∫–∞–Ω–∞–ª","–∫–∞–Ω–∞–ª –ø—Ä–æ–¥–∞–∂","—Ä–æ–∑–Ω–∏—Ü–∞","marketplace"],"business_field_name":"–ö–∞–Ω–∞–ª –ø—Ä–æ–¥–∞–∂","business_algorithm":"–°–ø—Ä–∞–≤–æ—á–Ω–∏–∫ –∫–∞–Ω–∞–ª–æ–≤"},
        {"dataset_id":17,"schema":"dm","table":"customer_dim","column":"customer_id","dtype":"string","completeness":0.99,"uniqueness":1.00,"tags":["–∫–ª–∏–µ–Ω—Ç","customer","–∏–¥ –∫–ª–∏–µ–Ω—Ç–∞"],"business_field_name":"–ö–ª–∏–µ–Ω—Ç","business_algorithm":"Master ID"},
        {"dataset_id":12,"schema":"raw","table":"erp_costs","column":"cogs","dtype":"decimal","completeness":0.92,"uniqueness":0.90,"tags":["—Å–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å","cogs","–∑–∞—Ç—Ä–∞—Ç—ã"],"business_field_name":"–°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å","business_algorithm":"ERP COGS"},
        {"dataset_id":12,"schema":"raw","table":"erp_costs","column":"sku","dtype":"string","completeness":0.94,"uniqueness":0.80,"tags":["sku","—Ç–æ–≤–∞—Ä","–∞—Ä—Ç–∏–∫—É–ª"],"business_field_name":"SKU","business_algorithm":"ERP SKU"},
        {"dataset_id":14,"schema":"raw","table":"crm_events","column":"event_type","dtype":"string","completeness":0.91,"uniqueness":0.65,"tags":["—Å–æ–±—ã—Ç–∏–µ","email","push","–∫–∞–º–ø–∞–Ω–∏—è"],"business_field_name":"–¢–∏–ø —Å–æ–±—ã—Ç–∏—è","business_algorithm":"CRM event type"},
    ])
    return datasets, reports, report_fields, dataset_fields

# ============================ SESSION STATE ===================================
if "datasets" not in st.session_state:
    st.session_state.datasets, st.session_state.reports, st.session_state.report_fields, st.session_state.dataset_fields = load_default_frames()
if "selected_refs" not in st.session_state:
    st.session_state.selected_refs = []

datasets = st.session_state.datasets
reports = st.session_state.reports
report_fields = st.session_state.report_fields
dataset_fields = st.session_state.dataset_fields

# –°–ª—É–∂–µ–±–Ω—ã–µ –ø–æ–ª—è
dataset_fields["ref"] = dataset_fields["schema"] + "." + dataset_fields["table"] + "." + dataset_fields["column"]
ref_to_dataset = {r["ref"]: r["dataset_id"] for _, r in dataset_fields.iterrows()}

# –°—Ç—Ä–æ–∏–º/–ø–µ—Ä–µ—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ø–æ–∏—Å–∫–æ–≤—ã–π –∏–Ω–¥–µ–∫—Å
if "vectorizer" not in st.session_state or "tfidf" not in st.session_state:
    st.session_state.vectorizer, st.session_state.tfidf = build_search_index(dataset_fields, datasets)

vectorizer = st.session_state.vectorizer
tfidf = st.session_state.tfidf

# =============================== –ù–ê–í–ò–ì–ê–¶–ò–Ø ====================================
page = st.sidebar.radio("–°—Ç—Ä–∞–Ω–∏—Ü—ã", ["–ì–ª–∞–≤–Ω–∞—è", "–ò–º–ø–æ—Ä—Ç/–≠–∫—Å–ø–æ—Ä—Ç"])

# ================================== –ì–õ–ê–í–ù–ê–Ø ===================================
if page == "–ì–ª–∞–≤–Ω–∞—è":
    st.title("–ö–∞—Ç–∞–ª–æ–≥ –¥–∞–Ω–Ω—ã—Ö –∏ –æ—Ç—á—ë—Ç–æ–≤ ‚Üí –ü–æ–¥–±–æ—Ä –ø–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º, –ø—Ä–æ—Ç–æ—Ç–∏–ø –∏ –ª–∏–Ω–µ–π–Ω–æ—Å—Ç—å")
    st.caption("–ü–æ–¥–±–µ—Ä–∏—Ç–µ –ø–æ–ª—è –∏ —Å–æ–±–µ—Ä–∏—Ç–µ –ø—Ä–æ—Ç–æ—Ç–∏–ø –æ—Ç—á—ë—Ç–∞, –Ω–µ –∑–Ω–∞—è –∑–∞—Ä–∞–Ω–µ–µ —Å—Ö–µ–º—ã –∏ —Ç–∞–±–ª–∏—Ü—ã.")

    # –¢–∞–±—ã
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "üîé –ü–æ–¥–±–æ—Ä –ø–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º",
        "üß± –í–∏—Ç—Ä–∏–Ω—ã",
        "üìã –†–µ–µ—Å—Ç—Ä –æ—Ç—á—ë—Ç–æ–≤",
        "üóÇÔ∏è –ê—Ç—Ä–∏–±—É—Ç—ã –æ—Ç—á—ë—Ç–∞",
        "üß≠ –õ–∏–Ω–µ–π–Ω–æ—Å—Ç—å"
    ])

    # ------------------- TAB 1: –ü–æ–¥–±–æ—Ä –ø–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º -------------------------
    with tab1:
        st.subheader("–û–ø–∏—à–∏—Ç–µ —á—Ç–æ –≤—ã —Ö–æ—Ç–∏—Ç–µ")
        st.caption("–í–≤–µ–¥–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏—è –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π, –∏–∑–º–µ—Ä–µ–Ω–∏–π, —Å–∏—Å—Ç–µ–º –∏–ª–∏ —Ç–∞–±–ª–∏—Ü (–Ω–∞–ø—Ä–∏–º–µ—Ä: ¬´–≤—ã—Ä—É—á–∫–∞¬ª, ¬´–∫–∞–Ω–∞–ª –ø—Ä–æ–¥–∞–∂¬ª, ¬´ERP —Å–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å¬ª).")

        q = st.text_input("–ü–æ–∏—Å–∫ –ø–æ –ø–æ–ª—è–º (—Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π TF-IDF)", placeholder="–ù–∞–ø—Ä–∏–º–µ—Ä: –≤—ã—Ä—É—á–∫–∞, –∫–∞–Ω–∞–ª –ø—Ä–æ–¥–∞–∂, —Ä–µ–≥–∏–æ–Ω, —Å–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å ...")
        cols = st.columns([3,1])
        with cols[0]:
            if q:
                results = search_fields(q, dataset_fields, vectorizer, tfidf, top_k=50)
                if results:
                    st.write("–ù–∞–π–¥–µ–Ω–Ω—ã–µ –ø–æ–ª—è:")
                    for ref, sc in results:
                        ds_id = ref_to_dataset[ref]
                        ds = datasets[datasets.dataset_id==ds_id].iloc[0]
                        row = dataset_fields.set_index("ref").loc[ref]
                        add_key = f"add_{ref}"
                        with st.container():
                            c1, c2, c3, c4, c5 = st.columns([3,2,1,1,1])
                            c1.markdown(f"**{row.get('business_field_name','')}**  \n`{ref}`")
                            c2.markdown(f"–°–∏—Å—Ç–µ–º–∞: **{ds['system']}**  \n–ù–∞–±–æ—Ä: `{ds['name']}`")
                            c3.markdown(f"–°–ª–æ–π: `{ds['layer']}`")
                            c4.markdown(f"DQ: **{row['completeness']:.2f}**")
                            c5.markdown(f"score: {sc:.2f}")
                            if st.button("–î–æ–±–∞–≤–∏—Ç—å –≤ –ø—Ä–æ—Ç–æ—Ç–∏–ø", key=add_key):
                                if ref not in st.session_state.selected_refs:
                                    st.session_state.selected_refs.append(ref)
                else:
                    st.info("–ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–∏–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏.")
            else:
                st.caption("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ—è–≤—è—Ç—Å—è –ø–æ—Å–ª–µ –≤–≤–æ–¥–∞ –ø–æ–∏—Å–∫–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞.")

        with cols[1]:
            if st.button("–û—á–∏—Å—Ç–∏—Ç—å –≤—ã–±—Ä–∞–Ω–Ω—ã–µ"):
                st.session_state.selected_refs = []

        st.markdown("---")
        st.markdown("### –ü—Ä–æ—Ç–æ—Ç–∏–ø –æ—Ç—á—ë—Ç–∞")
        if not st.session_state.selected_refs:
            st.info("–î–æ–±–∞–≤–ª—è–π—Ç–µ –ø–æ–ª—è –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞ ‚Äî –æ–Ω–∏ –ø–æ—è–≤—è—Ç—Å—è –≤ —Ç–∞–±–ª–∏—Ü–µ –Ω–∏–∂–µ.")
        else:
            # –¢–∞–±–ª–∏—Ü–∞ –ø—Ä–æ—Ç–æ—Ç–∏–ø–∞ —Å —Ç—Ä–µ–±—É–µ–º—ã–º–∏ –∫–æ–ª–æ–Ω–∫–∞–º–∏
            rows = []
            for i, ref in enumerate(st.session_state.selected_refs, start=1):
                ds_id = ref_to_dataset[ref]
                ds = datasets[datasets.dataset_id==ds_id].iloc[0]
                rf = report_fields[report_fields["source_ref"]==ref]
                used_ids = rf["report_id"].tolist()
                used_names = reports[reports["report_id"].isin(used_ids)]["name"].tolist()
                row = dataset_fields.set_index("ref").loc[ref]
                rows.append({
                    "‚Ññ": i,
                    "–ë–∏–∑–Ω–µ—Å-–ø–æ–ª–µ": row.get("business_field_name",""),
                    "–ë–∏–∑–Ω–µ—Å-–∞–ª–≥–æ—Ä–∏—Ç–º": row.get("business_algorithm",""),
                    "–ò—Å—Ç–æ—á–Ω–∏–∫ (schema.table.column)": ref,
                    "–°–≤—è–∑—å —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–æ–π —Å–∏—Å—Ç–µ–º–æ–π": ds["system"],
                    "–í –∫–∞–∫—É—é —Ç–∞–±–ª–∏—Ü—É –≤—Ö–æ–¥–∏—Ç": f"{row['schema']}.{row['table']}",
                    "–í –∫–∞–∫–∏—Ö –æ—Ç—á—ë—Ç–∞—Ö –µ—Å—Ç—å (ID)": ", ".join(map(str, used_ids)) if used_ids else "‚Äî",
                    "–ù–∞–∑–≤–∞–Ω–∏—è –æ—Ç—á—ë—Ç–æ–≤": ", ".join(used_names) if used_names else "‚Äî",
                })
            df_proto = pd.DataFrame(rows)
            st.dataframe(df_proto, use_container_width=True, height=360)
            download_button_for_df(df_proto, "‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å –ø—Ä–æ—Ç–æ—Ç–∏–ø (Excel)", "prototype.xlsx")

    # ------------------- TAB 2: –í–∏—Ç—Ä–∏–Ω—ã --------------------------------------
    with tab2:
        c1, c2 = st.columns(2)
        with c1:
            st.write("**–í–∏—Ç—Ä–∏–Ω–∞ (dm.*)**")
            st.dataframe(datasets.query("layer=='vitrine'")[["name","system","owner","sla_minutes","pii_flags","quality_score","granularity"]]
                         .rename(columns={"name":"–ù–∞–±–æ—Ä","system":"–°–∏—Å—Ç–µ–º–∞","owner":"–í–ª–∞–¥–µ–ª–µ—Ü","sla_minutes":"SLA (–º–∏–Ω)","pii_flags":"PII","quality_score":"–ö–∞—á–µ—Å—Ç–≤–æ","granularity":"–ì—Ä–∞–Ω—É–ª—è—Ä–Ω–æ—Å—Ç—å"}),
                         use_container_width=True, height=260)
        with c2:
            st.write("**–ò—Å—Ç–æ—á–Ω–∏–∫–∏ (RAW/Source)**")
            st.dataframe(datasets.query("layer!='vitrine'")[["name","system","owner","sla_minutes","pii_flags","quality_score","granularity"]]
                         .rename(columns={"name":"–ù–∞–±–æ—Ä","system":"–°–∏—Å—Ç–µ–º–∞","owner":"–í–ª–∞–¥–µ–ª–µ—Ü","sla_minutes":"SLA (–º–∏–Ω)","pii_flags":"PII","quality_score":"–ö–∞—á–µ—Å—Ç–≤–æ","granularity":"–ì—Ä–∞–Ω—É–ª—è—Ä–Ω–æ—Å—Ç—å"}),
                         use_container_width=True, height=260)

        st.markdown("### –ü–æ–ª—è")
        df_fields = dataset_fields.copy()
        df_fields.insert(0, "‚Ññ", range(1, len(df_fields)+1))
        # –ö–æ–ª–æ–Ω–∫–∏: –ø–æ—Å–ª–µ –Ω—É–º–µ—Ä–∞—Ü–∏–∏ ‚Äî –ë–∏–∑–Ω–µ—Å-–ø–æ–ª–µ, –ë–∏–∑–Ω–µ—Å-–∞–ª–≥–æ—Ä–∏—Ç–º, –∑–∞—Ç–µ–º —Å—Ö–µ–º–∞/—Ç–∞–±–ª–∏—Ü–∞/–ø–æ–ª–µ –∏ –ø—Ä.
        df_fields = df_fields[["‚Ññ","business_field_name","business_algorithm","schema","table","column","dtype","completeness","uniqueness","tags"]]
        df_fields = df_fields.rename(columns={
            "business_field_name":"–ë–∏–∑–Ω–µ—Å-–ø–æ–ª–µ",
            "business_algorithm":"–ë–∏–∑–Ω–µ—Å-–∞–ª–≥–æ—Ä–∏—Ç–º",
            "schema":"–°—Ö–µ–º–∞","table":"–¢–∞–±–ª–∏—Ü–∞","column":"–ü–æ–ª–µ","dtype":"–¢–∏–ø",
            "completeness":"–ü–æ–ª–Ω–æ—Ç–∞","uniqueness":"–£–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å","tags":"–¢–µ–≥–∏"
        })
        st.dataframe(df_fields, use_container_width=True, height=360)

    # ------------------- TAB 3: –†–µ–µ—Å—Ç—Ä –æ—Ç—á—ë—Ç–æ–≤ (–ø–æ–∏—Å–∫–æ–≤—ã–π —Ñ–∏–ª—å—Ç—Ä) -------------
    with tab3:
        st.write("### –†–µ–µ—Å—Ç—Ä –æ—Ç—á—ë—Ç–æ–≤")
        query = st.text_input("–§–∏–ª—å—Ç—Ä –ø–æ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏—é/–≤–ª–∞–¥–µ–ª—å—Ü—É/–¥–æ–º–µ–Ω—É", "")
        show = reports.copy()
        if query:
            ql = query.lower()
            mask = (
                show["name"].str.lower().str.contains(ql) |
                show["owner"].str.lower().str.contains(ql) |
                show["business_domain"].str.lower().str.contains(ql)
            )
            show = show[mask]
        grid = show[["name","owner","business_domain","frequency","is_automated","automation_score","description"]].rename(
            columns={"name":"–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ","owner":"–í–ª–∞–¥–µ–ª–µ—Ü","business_domain":"–î–æ–º–µ–Ω","frequency":"–ß–∞—Å—Ç–æ—Ç–∞","is_automated":"–ê–≤—Ç–æ?","automation_score":"–°–∫–æ—Ä","description":"–û–ø–∏—Å–∞–Ω–∏–µ"})
        st.dataframe(grid, use_container_width=True, height=300)

    # ------------------- TAB 4: –ê—Ç—Ä–∏–±—É—Ç—ã –æ—Ç—á—ë—Ç–∞ (–ø–æ–∏—Å–∫ + –≤—ã–≥—Ä—É–∑–∫–∞) ------------
    with tab4:
        selected = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –æ—Ç—á—ë—Ç", options=reports["name"].tolist())
        rep = reports[reports["name"]==selected].iloc[0]
        rid = rep["report_id"]
        st.write(f"**–í–ª–∞–¥–µ–ª–µ—Ü:** {rep['owner']}  ¬∑  **–ß–∞—Å—Ç–æ—Ç–∞:** {rep['frequency']}  ¬∑  **–°—Ç–∞—Ç—É—Å:** {'–ê–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω' if rep['is_automated'] else '–†—É—á–Ω–æ–π'}")
        st.caption(rep["description"])

        rf = report_fields[report_fields["report_id"]==rid].copy()
        rf["–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –æ—Ç—á—ë—Ç–∞"] = rep["name"]
        rf = rf.rename(columns={
            "report_id":"–ö–æ–¥ –æ—Ç—á—ë—Ç–∞",
            "business_field_name":"–ë–∏–∑–Ω–µ—Å-–ø–æ–ª–µ",
            "business_algorithm":"–ë–∏–∑–Ω–µ—Å-–∞–ª–≥–æ—Ä–∏—Ç–º",
            "source_ref":"–ò—Å—Ç–æ—á–Ω–∏–∫ (schema.table.column)",
            "is_from_vitrine":"–ò–∑ –≤–∏—Ç—Ä–∏–Ω—ã?"
        })
        # –ü–æ—Ä—è–¥–æ–∫: –ë–∏–∑–Ω–µ—Å-–∞–ª–≥–æ—Ä–∏—Ç–º ‚Üí –ö–æ–¥ –æ—Ç—á—ë—Ç–∞ ‚Üí –ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –æ—Ç—á—ë—Ç–∞ ‚Üí ...
        rf = rf[["–ë–∏–∑–Ω–µ—Å-–ø–æ–ª–µ","–ë–∏–∑–Ω–µ—Å-–∞–ª–≥–æ—Ä–∏—Ç–º","–ö–æ–¥ –æ—Ç—á—ë—Ç–∞","–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –æ—Ç—á—ë—Ç–∞","–ò—Å—Ç–æ—á–Ω–∏–∫ (schema.table.column)","–ò–∑ –≤–∏—Ç—Ä–∏–Ω—ã?"]]

        attr_filter = st.text_input("–§–∏–ª—å—Ç—Ä –ø–æ –∞—Ç—Ä–∏–±—É—Ç–∞–º (–ø–æ–ª–µ/–∞–ª–≥–æ—Ä–∏—Ç–º/–∏—Å—Ç–æ—á–Ω–∏–∫)")
        if attr_filter:
            ql = attr_filter.lower()
            mask = (
                rf["–ë–∏–∑–Ω–µ—Å-–ø–æ–ª–µ"].str.lower().str.contains(ql) |
                rf["–ë–∏–∑–Ω–µ—Å-–∞–ª–≥–æ—Ä–∏—Ç–º"].str.lower().str.contains(ql) |
                rf["–ò—Å—Ç–æ—á–Ω–∏–∫ (schema.table.column)"].str.lower().str.contains(ql)
            )
            rf_view = rf[mask]
        else:
            rf_view = rf

        st.dataframe(rf_view, use_container_width=True, height=280)
        download_button_for_df(rf_view, "‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å –∞—Ç—Ä–∏–±—É—Ç—ã –æ—Ç—á—ë—Ç–∞ (Excel)", f"report_{rid}_attrs.xlsx")

    # ------------------- TAB 5: –õ–∏–Ω–µ–π–Ω–æ—Å—Ç—å -----------------------------------
    with tab5:
        st.subheader("Data Lineage")

        mode = st.radio("–†–µ–∂–∏–º", ["–ì–ª–æ–±–∞–ª—å–Ω–æ", "–ü–æ –æ—Ç—á—ë—Ç—É"], horizontal=True)
        if mode == "–ü–æ –æ—Ç—á—ë—Ç—É":
            rep_name = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –æ—Ç—á—ë—Ç", options=reports["name"].tolist())
            rid = int(reports[reports["name"]==rep_name].iloc[0]["report_id"])
        else:
            rid = None

        edges_all = build_lineage_edges(dataset_fields, report_fields)
        edges = filter_edges_by_report(edges_all, rid) if rid else edges_all

        viz = st.radio("–¢–∏–ø –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏", ["–ì—Ä–∞—Ñ (–∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π)", "Sankey"], horizontal=True)

        if viz == "–ì—Ä–∞—Ñ (–∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π)":
            net = pyvis_graph(edges, reports, datasets, height="650px")
            html = net.generate_html(notebook=False)
            components.html(html, height=680, scrolling=True)
            st.download_button(
                "‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å –≥—Ä–∞—Ñ (HTML)",
                data=html.encode("utf-8"),
                file_name=f"lineage_{'report_'+str(rid) if rid else 'global'}.html",
                mime="text/html"
            )
        else:
            fig = sankey_figure(edges)
            st.plotly_chart(fig, use_container_width=True)

# ============================== –ò–ú–ü–û–†–¢ / –≠–ö–°–ü–û–†–¢ ==============================
else:
    st.title("–ò–º–ø–æ—Ä—Ç/–≠–∫—Å–ø–æ—Ä—Ç")
    st.caption("–ó–∞–≥—Ä—É–∑–∏—Ç–µ Excel-—Ñ–∞–π–ª—ã, —á—Ç–æ–±—ã –∑–∞–º–µ–Ω–∏—Ç—å —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ. –¢–∞–∫–∂–µ –º–æ–∂–Ω–æ —Å–∫–∞—á–∞—Ç—å —à–∞–±–ª–æ–Ω—ã –¥–ª—è –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è.")

    st.markdown("#### –®–∞–±–ª–æ–Ω—ã –¥–ª—è –≤—ã–≥—Ä—É–∑–∫–∏")
    template_datasets = pd.DataFrame([{
        "dataset_id":"","name":"","layer":"","owner":"","sla_minutes":"","pii_flags":"","quality_score":"","granularity":"","system":""
    }])
    template_dataset_fields = pd.DataFrame([{
        "dataset_id":"","schema":"","table":"","column":"","dtype":"",
        "completeness":"","uniqueness":"","tags":"—Å–ø–∏—Å–æ–∫_—á–µ—Ä–µ–∑_–∑–∞–ø—è—Ç—É—é",
        "business_field_name":"","business_algorithm":""
    }])
    template_reports = pd.DataFrame([{
        "report_id":"","name":"","owner":"","frequency":"","business_domain":"",
        "is_automated":"","automation_score":"","description":""
    }])
    template_report_fields = pd.DataFrame([{
        "report_id":"","business_field_name":"","business_algorithm":"",
        "source_ref":"","is_from_vitrine":""
    }])

    c1, c2, c3, c4 = st.columns(4)
    with c1: download_button_for_df(template_datasets, "‚¨áÔ∏è –®–∞–±–ª–æ–Ω: datasets.xlsx", "datasets_template.xlsx")
    with c2: download_button_for_df(template_dataset_fields, "‚¨áÔ∏è –®–∞–±–ª–æ–Ω: dataset_fields.xlsx", "dataset_fields_template.xlsx")
    with c3: download_button_for_df(template_reports, "‚¨áÔ∏è –®–∞–±–ª–æ–Ω: reports.xlsx", "reports_template.xlsx")
    with c4: download_button_for_df(template_report_fields, "‚¨áÔ∏è –®–∞–±–ª–æ–Ω: report_fields.xlsx", "report_fields_template.xlsx")

    st.markdown("---")
    st.markdown("#### –ò–º–ø–æ—Ä—Ç Excel")
    st.caption("–û–∂–∏–¥–∞—é—Ç—Å—è –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã —Å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–º–∏ —Å—Ç–æ–ª–±—Ü–∞–º–∏. –¢–µ–≥–∏ –º–æ–∂–Ω–æ —É–∫–∞–∑—ã–≤–∞—Ç—å —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é.")

    up1 = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ datasets.xlsx", type=["xlsx"])
    up2 = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ dataset_fields.xlsx", type=["xlsx"])
    up3 = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ reports.xlsx", type=["xlsx"])
    up4 = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ report_fields.xlsx", type=["xlsx"])

    if st.button("–ó–∞–º–µ–Ω–∏—Ç—å —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –Ω–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ"):
        try:
            if up1: st.session_state.datasets = pd.read_excel(up1)
            if up2:
                df = pd.read_excel(up2)
                if "tags" in df.columns:
                    df["tags"] = df["tags"].apply(lambda x: [t.strip() for t in str(x).split(",")] if pd.notna(x) else [])
                st.session_state.dataset_fields = df
            if up3: st.session_state.reports = pd.read_excel(up3)
            if up4: st.session_state.report_fields = pd.read_excel(up4)

            # –ü–µ—Ä–µ—Å–æ–±–µ—Ä—ë–º —Å–ª—É–∂–µ–±–Ω—ã–µ –ø–æ–ª—è/–∏–Ω–¥–µ–∫—Å
            st.session_state.dataset_fields["ref"] = (
                st.session_state.dataset_fields["schema"] + "." +
                st.session_state.dataset_fields["table"] + "." +
                st.session_state.dataset_fields["column"]
            )
            st.session_state.vectorizer, st.session_state.tfidf = build_search_index(
                st.session_state.dataset_fields, st.session_state.datasets
            )
            st.success("–î–∞–Ω–Ω—ã–µ –æ–±–Ω–æ–≤–ª–µ–Ω—ã. –ü–µ—Ä–µ–π–¥–∏—Ç–µ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É ¬´–ì–ª–∞–≤–Ω–∞—è¬ª.")
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}")
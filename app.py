# app.py
import streamlit as st
import pandas as pd
import numpy as np
from collections import defaultdict
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

st.set_page_config(page_title="DWH ‚Üí –ü–æ–¥–±–æ—Ä –ø–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º –∏ –ø—Ä–æ—Ç–æ—Ç–∏–ø –æ—Ç—á—ë—Ç–∞", layout="wide")

# ------------------------------ –¢–ï–°–¢–û–í–´–ï –î–ê–ù–ù–´–ï -----------------------------------
# –î–æ–±–∞–≤–∏–ª–∏ –∫–æ–ª–æ–Ω–∫—É 'system' –¥–ª—è —Å–≤—è–∑–∏ —Å –ò–°
datasets = pd.DataFrame([
    {"dataset_id": 10, "name": "dm.sales_facts",    "layer": "vitrine", "owner": "DWH",     "sla_minutes": 120,  "pii_flags": "",     "quality_score": 0.93, "granularity": "txn_day_sku", "system": "DWH / Sales Mart"},
    {"dataset_id": 11, "name": "dm.customer_facts", "layer": "vitrine", "owner": "DWH",     "sla_minutes": 1440, "pii_flags": "PII",  "quality_score": 0.88, "granularity": "customer_month","system": "DWH / CRM Mart"},
    {"dataset_id": 12, "name": "raw.erp_costs",     "layer": "raw",     "owner": "DataOps", "sla_minutes": 60,   "pii_flags": "",     "quality_score": 0.76, "granularity": "sku_day",      "system": "ERP"},
    {"dataset_id": 13, "name": "dm.finance_facts",  "layer": "vitrine", "owner": "DWH",     "sla_minutes": 1440, "pii_flags": "",     "quality_score": 0.86, "granularity": "dept_month",   "system": "DWH / Finance Mart"},
    {"dataset_id": 14, "name": "raw.crm_events",    "layer": "raw",     "owner": "MarTech", "sla_minutes": 30,   "pii_flags": "PII",  "quality_score": 0.71, "granularity": "event",        "system": "CRM"},
    {"dataset_id": 15, "name": "dm.geo_dim",        "layer": "vitrine", "owner": "DWH",     "sla_minutes": 1440, "pii_flags": "",     "quality_score": 0.95, "granularity": "region",       "system": "DWH / Master Data"},
    {"dataset_id": 16, "name": "dm.sales_dim",      "layer": "vitrine", "owner": "DWH",     "sla_minutes": 1440, "pii_flags": "",     "quality_score": 0.92, "granularity": "channel",      "system": "DWH / Master Data"},
    {"dataset_id": 17, "name": "dm.customer_dim",   "layer": "vitrine", "owner": "DWH",     "sla_minutes": 1440, "pii_flags": "PII",  "quality_score": 0.90, "granularity": "customer",     "system": "DWH / Master Data"},
])

reports = pd.DataFrame([
    {"report_id": 1, "name": "–ü—Ä–æ–¥–∞–∂–∏ –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º",          "owner": "BI Team", "frequency": "–ï–∂–µ–¥–Ω–µ–≤–Ω–æ",   "business_domain": "Sales",   "is_automated": True,  "automation_score": 92, "description": "–í–æ—Ä–æ–Ω–∫–∞ –ø—Ä–æ–¥–∞–∂ –∏ –≤—ã—Ä—É—á–∫–∞ –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º –∏ –∫–∞–Ω–∞–ª–∞–º."},
    {"report_id": 2, "name": "–ú–∞—Ä–∂–∏–Ω–∞–ª—å–Ω–æ—Å—Ç—å SKU (—Ä—É—á–Ω–æ–π)",  "owner": "Finance", "frequency": "–ï–∂–µ–Ω–µ–¥–µ–ª—å–Ω–æ", "business_domain": "Finance", "is_automated": False, "automation_score": 58, "description": "–†—É—á–Ω–æ–π excel –ø–æ –º–∞—Ä–∂–µ –∏ —Å–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç–∏ –Ω–∞ —É—Ä–æ–≤–Ω–µ SKU."},
    {"report_id": 3, "name": "Churn –¥–∞—à–±–æ—Ä–¥",                 "owner": "CRM",     "frequency": "–ï–∂–µ–º–µ—Å—è—á–Ω–æ",  "business_domain": "CRM",     "is_automated": True,  "automation_score": 81, "description": "–û—Ç—á—ë—Ç –ø–æ –æ—Ç—Ç–æ–∫—É –∫–ª–∏–µ–Ω—Ç–æ–≤, —Ä–µ—Ç–µ–Ω—à–Ω –∏ —Å–µ–≥–º–µ–Ω—Ç—ã."},
    {"report_id": 4, "name": "–ü–ª–∞–Ω/–§–∞–∫—Ç –î–æ—Ö–æ–¥–æ–≤",             "owner": "FP&A",    "frequency": "–ï–∂–µ–º–µ—Å—è—á–Ω–æ",  "business_domain": "Finance", "is_automated": True,  "automation_score": 76, "description": "–°–≤–æ–¥ –¥–æ—Ö–æ–¥–æ–≤ –ø—Ä–æ—Ç–∏–≤ –±—é–¥–∂–µ—Ç–∞ –ø–æ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è–º."},
])

report_fields = pd.DataFrame([
    {"report_id": 1, "business_field_name": "–í—ã—Ä—É—á–∫–∞",                 "source_ref": "dm.sales_facts.revenue",            "is_from_vitrine": True},
    {"report_id": 1, "business_field_name": "–ö–∞–Ω–∞–ª –ø—Ä–æ–¥–∞–∂",            "source_ref": "dm.sales_dim.channel",              "is_from_vitrine": True},
    {"report_id": 1, "business_field_name": "–†–µ–≥–∏–æ–Ω",                  "source_ref": "dm.geo_dim.region_name",            "is_from_vitrine": True},
    {"report_id": 2, "business_field_name": "SKU",                     "source_ref": "raw.erp_costs.sku",                 "is_from_vitrine": False},
    {"report_id": 2, "business_field_name": "–°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å",           "source_ref": "raw.erp_costs.cogs",                "is_from_vitrine": False},
    {"report_id": 2, "business_field_name": "–¶–µ–Ω–∞ –ø—Ä–æ–¥–∞–∂–∏",            "source_ref": "dm.sales_facts.price",              "is_from_vitrine": True},
    {"report_id": 3, "business_field_name": "–ö–ª–∏–µ–Ω—Ç",                  "source_ref": "dm.customer_dim.customer_id",       "is_from_vitrine": True},
    {"report_id": 3, "business_field_name": "–°—Ç–∞—Ç—É—Å –æ—Ç—Ç–æ–∫–∞",           "source_ref": "dm.customer_facts.churn_flag",      "is_from_vitrine": True},
    {"report_id": 3, "business_field_name": "–î–∞—Ç–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–π –ø–æ–∫—É–ø–∫–∏",  "source_ref": "dm.customer_facts.last_purchase_dt","is_from_vitrine": True},
    {"report_id": 4, "business_field_name": "–î–æ—Ö–æ–¥ —Ñ–∞–∫—Ç",              "source_ref": "dm.finance_facts.revenue_actual",   "is_from_vitrine": True},
    {"report_id": 4, "business_field_name": "–î–æ—Ö–æ–¥ –ø–ª–∞–Ω",              "source_ref": "dm.finance_facts.revenue_budget",   "is_from_vitrine": True},
])

dataset_fields = pd.DataFrame([
    {"dataset_id": 10, "schema": "dm",  "table": "sales_facts",    "column": "revenue",           "dtype": "decimal", "completeness": 0.99, "uniqueness": 0.95, "tags": ["–≤—ã—Ä—É—á–∫–∞","–¥–æ—Ö–æ–¥","–æ–±–æ—Ä–æ—Ç","revenue","sales"]},
    {"dataset_id": 10, "schema": "dm",  "table": "sales_facts",    "column": "price",             "dtype": "decimal", "completeness": 0.98, "uniqueness": 0.92, "tags": ["—Ü–µ–Ω–∞","price","—Å—Ç–æ–∏–º–æ—Å—Ç—å –ø—Ä–æ–¥–∞–∂–∏"]},
    {"dataset_id": 10, "schema": "dm",  "table": "sales_facts",    "column": "sku_id",            "dtype": "string",  "completeness": 0.97, "uniqueness": 0.80, "tags": ["sku","—Ç–æ–≤–∞—Ä","–∞—Ä—Ç–∏–∫—É–ª"]},
    {"dataset_id": 10, "schema": "dm",  "table": "sales_facts",    "column": "channel",           "dtype": "string",  "completeness": 0.98, "uniqueness": 0.70, "tags": ["–∫–∞–Ω–∞–ª","–æ–Ω–ª–∞–π–Ω","–æ—Ñ—Ñ–ª–∞–π–Ω","—Ä–æ–∑–Ω–∏—Ü–∞","ecom"]},
    {"dataset_id": 10, "schema": "dm",  "table": "sales_facts",    "column": "region_id",         "dtype": "int",     "completeness": 0.98, "uniqueness": 0.60, "tags": ["—Ä–µ–≥–∏–æ–Ω","–≥–µ–æ","–æ–±–ª–∞—Å—Ç—å"]},
    {"dataset_id": 11, "schema": "dm",  "table": "customer_facts", "column": "churn_flag",        "dtype": "bool",    "completeness": 0.97, "uniqueness": 1.00, "tags": ["–æ—Ç—Ç–æ–∫","churn","—É—à—ë–ª","—É–¥–µ—Ä–∂–∞–Ω–∏–µ"]},
    {"dataset_id": 11, "schema": "dm",  "table": "customer_facts", "column": "last_purchase_dt",  "dtype": "date",    "completeness": 0.96, "uniqueness": 0.90, "tags": ["–ø–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–∫—É–ø–∫–∞","recency","lrp"]},
    {"dataset_id": 13, "schema": "dm",  "table": "finance_facts",  "column": "revenue_actual",    "dtype": "decimal", "completeness": 0.98, "uniqueness": 0.95, "tags": ["–¥–æ—Ö–æ–¥ —Ñ–∞–∫—Ç","—Ñ–∞–∫—Ç","actual","–≤—ã—Ä—É—á–∫–∞"]},
    {"dataset_id": 13, "schema": "dm",  "table": "finance_facts",  "column": "revenue_budget",    "dtype": "decimal", "completeness": 0.98, "uniqueness": 0.95, "tags": ["–ø–ª–∞–Ω –¥–æ—Ö–æ–¥","–±—é–¥–∂–µ—Ç","budget"]},
    {"dataset_id": 15, "schema": "dm",  "table": "geo_dim",        "column": "region_name",       "dtype": "string",  "completeness": 0.99, "uniqueness": 0.95, "tags": ["—Ä–µ–≥–∏–æ–Ω","–≥–µ–æ–≥—Ä–∞—Ñ–∏—è","—Ä–µ–≥–∏–æ–Ω –Ω–∞–∑–≤–∞–Ω–∏–µ"]},
    {"dataset_id": 16, "schema": "dm",  "table": "sales_dim",      "column": "channel",           "dtype": "string",  "completeness": 0.99, "uniqueness": 0.95, "tags": ["–∫–∞–Ω–∞–ª","–∫–∞–Ω–∞–ª –ø—Ä–æ–¥–∞–∂","—Ä–æ–∑–Ω–∏—Ü–∞","marketplace"]},
    {"dataset_id": 17, "schema": "dm",  "table": "customer_dim",   "column": "customer_id",       "dtype": "string",  "completeness": 0.99, "uniqueness": 1.00, "tags": ["–∫–ª–∏–µ–Ω—Ç","customer","–∏–¥ –∫–ª–∏–µ–Ω—Ç–∞"]},
    {"dataset_id": 12, "schema": "raw", "table": "erp_costs",      "column": "cogs",              "dtype": "decimal", "completeness": 0.92, "uniqueness": 0.90, "tags": ["—Å–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å","cogs","–∑–∞—Ç—Ä–∞—Ç—ã"]},
    {"dataset_id": 12, "schema": "raw", "table": "erp_costs",      "column": "sku",               "dtype": "string",  "completeness": 0.94, "uniqueness": 0.80, "tags": ["sku","—Ç–æ–≤–∞—Ä","–∞—Ä—Ç–∏–∫—É–ª"]},
    {"dataset_id": 14, "schema": "raw", "table": "crm_events",     "column": "event_type",        "dtype": "string",  "completeness": 0.91, "uniqueness": 0.65, "tags": ["—Å–æ–±—ã—Ç–∏–µ","email","push","–∫–∞–º–ø–∞–Ω–∏—è"]},
])

dataset_fields["ref"] = dataset_fields["schema"] + "." + dataset_fields["table"] + "." + dataset_fields["column"]
ref_to_dataset = {r["ref"]: r["dataset_id"] for _, r in dataset_fields.iterrows()}

# –ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è: —Ç–µ–∫—Å—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞ = column + tags + dataset name + system
def build_corpus_row(row):
    ds = datasets[datasets.dataset_id == row["dataset_id"]].iloc[0]
    parts = [
        row["column"],
        " ".join(row["tags"]),
        f"{row['schema']}.{row['table']}",
        ds["name"],
        ds["system"]
    ]
    return " ".join([str(x) for x in parts if x])

dataset_fields["search_text"] = dataset_fields.apply(build_corpus_row, axis=1)

# TF-IDF –∏–Ω–¥–µ–∫—Å
vectorizer = TfidfVectorizer(ngram_range=(1,2), analyzer="word", min_df=1)
tfidf = vectorizer.fit_transform(dataset_fields["search_text"].values)

# ------------------------------ –•–ï–õ–ü–ï–†–´ -----------------------------------
def search_fields(query: str, top_k: int = 20):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç top_k –ø–æ–ª–µ–π —Å –∫–æ—Å–∏–Ω—É—Å–Ω–æ–π –±–ª–∏–∑–æ—Å—Ç—å—é –ø–æ TF-IDF."""
    if not query.strip():
        return []
    q_vec = vectorizer.transform([query])
    sim = cosine_similarity(q_vec, tfidf).ravel()
    idx = np.argsort(sim)[::-1][:top_k]
    results = []
    for i in idx:
        results.append((dataset_fields.iloc[i]["ref"], float(sim[i])))
    return [r for r in results if r[1] > 0]

def status_label(score):
    if score >= 85: return "‚úÖ –ì–æ—Ç–æ–≤–æ"
    if score >= 60: return "üü° –ß–∞—Å—Ç–∏—á–Ω–æ"
    return "üî¥ –¢—Ä–µ–±—É–µ—Ç—Å—è –¥–æ—Ä–∞–±–æ—Ç–∫–∞"

def feasibility_score(found_refs, total_refs, allow_vitrine=True):
    if total_refs == 0:
        return 0, {}
    coverage = len(found_refs) / total_refs
    freshness = 0.8 if allow_vitrine else 0.9
    quality = float(np.mean([dataset_fields.set_index("ref").loc[r, "completeness"] for r in found_refs])) if found_refs else 0.5
    access = 0.9
    vit_share = sum(1 for r in found_refs if r.startswith("dm.")) / max(1,len(found_refs))
    reuse = 1.0 if vit_share >= 0.7 else 0.4
    score = (coverage*0.40 + freshness*0.20 + quality*0.15 + access*0.15 + reuse*0.10) * 100
    return round(score), {
        "–ü–æ–∫—Ä—ã—Ç–∏–µ –ø–æ–ª–µ–π": round(coverage*100),
        "–°–≤–µ–∂–µ—Å—Ç—å/SLA": round(freshness*100),
        "–ö–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö": round(quality*100),
        "–î–æ—Å—Ç—É–ø": round(access*100),
        "–ü–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ": round(reuse*100),
    }

def reports_for_ref(ref: str):
    used = report_fields[report_fields["source_ref"] == ref]["report_id"].tolist()
    names = reports[reports["report_id"].isin(used)]["name"].tolist()
    return used, names

# ------------------------------ –°–û–°–¢–û–Ø–ù–ò–ï -----------------------------------
if "selected_refs" not in st.session_state:
    st.session_state.selected_refs = []

# ------------------------------ HEADER ---------------------------------------
st.title("–ö–∞—Ç–∞–ª–æ–≥ –¥–∞–Ω–Ω—ã—Ö –∏ –æ—Ç—á—ë—Ç–æ–≤ ‚Üí –ü–æ–¥–±–æ—Ä –ø–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º –∏ —Å–±–æ—Ä–∫–∞ –ø—Ä–æ—Ç–æ—Ç–∏–ø–∞")
st.caption("–ü–æ–¥–±–µ—Ä–∏—Ç–µ –ø–æ–ª—è –∏ —Å–æ–±–µ—Ä–∏—Ç–µ –ø—Ä–æ—Ç–æ—Ç–∏–ø –æ—Ç—á—ë—Ç–∞, –Ω–µ –∑–Ω–∞—è –∑–∞—Ä–∞–Ω–µ–µ —Å—Ö–µ–º—ã –∏ —Ç–∞–±–ª–∏—Ü—ã.")

# ------------------------------ –¢–ê–ë–´ -----------------------------------------
tab1, tab2, tab3, tab4 = st.tabs(["üîé –ü–æ–¥–±–æ—Ä –ø–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º", "üß± –î–∞–Ω–Ω—ã–µ", "üìä –û—Ç—á—ë—Ç—ã", "üß™ –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–∏–≥–æ–¥–Ω–æ—Å—Ç–∏"])

# ------------------------------ TAB 1: –ü–û–î–ë–û–† –ü–û –ü–ê–†–ê–ú–ï–¢–†–ê–ú ------------------
with tab1:
    st.subheader("–û–ø–∏—à–∏—Ç–µ —á—Ç–æ –≤—ã —Ö–æ—Ç–∏—Ç–µ")
    st.caption("–ù–∞—á–Ω–∏—Ç–µ –≤–≤–æ–¥–∏—Ç—å –Ω–∞–∑–≤–∞–Ω–∏—è –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π, –∏–∑–º–µ—Ä–µ–Ω–∏–π, —Å–∏—Å—Ç–µ–º –∏–ª–∏ —Ç–∞–±–ª–∏—Ü (–Ω–∞–ø—Ä–∏–º–µ—Ä: ¬´–≤—ã—Ä—É—á–∫–∞¬ª, ¬´–∫–∞–Ω–∞–ª –ø—Ä–æ–¥–∞–∂¬ª, ¬´ERP —Å–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å¬ª, ¬´finance facts¬ª).")
    q = st.text_input("–ü–æ–∏—Å–∫ –ø–æ –ø–æ–ª—è–º (TF-IDF –∏–Ω–¥–µ–∫—Å)", placeholder="–ù–∞–ø—Ä–∏–º–µ—Ä: –≤—ã—Ä—É—á–∫–∞ –ø–æ –∫–∞–Ω–∞–ª–∞–º –∏ —Ä–µ–≥–∏–æ–Ω–∞–º, —Å–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å SKU ...")

    cols = st.columns([3,1])
    with cols[0]:
        if q:
            results = search_fields(q, top_k=30)
            if results:
                st.write("–ù–∞–π–¥–µ–Ω–Ω—ã–µ –ø–æ–ª—è:")
                for ref, sc in results:
                    ds_id = ref_to_dataset[ref]
                    ds = datasets[datasets.dataset_id==ds_id].iloc[0]
                    meta = dataset_fields.set_index("ref").loc[ref]
                    add_key = f"add_{ref}"
                    with st.container():
                        c1, c2, c3, c4, c5 = st.columns([3,2,1,1,1])
                        c1.markdown(f"**{ref.split('.')[-1]}**  \n`{ref}`")
                        c2.markdown(f"–ù–∞–±–æ—Ä: `{ds['name']}`  \n–°–∏—Å—Ç–µ–º–∞: **{ds['system']}**")
                        c3.markdown(f"–°–ª–æ–π: `{ds['layer']}`")
                        c4.markdown(f"DQ: **{meta['completeness']:.2f}**")
                        c5.markdown(f"score: {sc:.2f}")
                        if st.button("–î–æ–±–∞–≤–∏—Ç—å –≤ –ø—Ä–æ—Ç–æ—Ç–∏–ø", key=add_key):
                            if ref not in st.session_state.selected_refs:
                                st.session_state.selected_refs.append(ref)
            else:
                st.info("–ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–∏–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏ –∏–ª–∏ –±–æ–ª–µ–µ –æ–±—â–∏–π —Ç–µ—Ä–º–∏–Ω.")
        else:
            st.caption("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ—è–≤—è—Ç—Å—è –ø–æ—Å–ª–µ –≤–≤–æ–¥–∞ –ø–æ–∏—Å–∫–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞.")

    with cols[1]:
        if st.button("–û—á–∏—Å—Ç–∏—Ç—å –≤—ã–±—Ä–∞–Ω–Ω—ã–µ"):
            st.session_state.selected_refs = []

    st.markdown("---")
    st.markdown("### –ü—Ä–æ—Ç–æ—Ç–∏–ø –æ—Ç—á—ë—Ç–∞ (—Å–±–æ—Ä—â–∏–∫)")
    if not st.session_state.selected_refs:
        st.info("–ü–æ–∫–∞ –Ω–∏—á–µ–≥–æ –Ω–µ –≤—ã–±—Ä–∞–Ω–æ. –î–æ–±–∞–≤–ª—è–π—Ç–µ –ø–æ–ª—è –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞ ‚Äî –æ–Ω–∏ –ø–æ—è–≤—è—Ç—Å—è –∑–¥–µ—Å—å.")
    else:
        # –ü–æ—Å—Ç—Ä–æ–∏–º ¬´–≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—É—é —Ç–∞–±–ª–∏—Ü—É¬ª (–ø–æ —Å—Ç—Ä–æ–∫–µ –Ω–∞ –ø–æ–ª–µ) —Å –Ω—É–∂–Ω—ã–º–∏ –∫–æ–ª–æ–Ω–∫–∞–º–∏
        rows = []
        for ref in st.session_state.selected_refs:
            ds_id = ref_to_dataset[ref]
            ds = datasets[datasets.dataset_id==ds_id].iloc[0]
            used_ids, used_names = reports_for_ref(ref)
            rows.append({
                "–ü–æ–ª–µ": ref.split(".")[-1],
                "–°–≤—è–∑—å —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–æ–π —Å–∏—Å—Ç–µ–º–æ–π": ds["system"],
                "–í –∫–∞–∫—É—é —Ç–∞–±–ª–∏—Ü—É –≤—Ö–æ–¥–∏—Ç": f"{ref.split('.')[0]}.{ref.split('.')[1]}",
                "–ò—Å—Ç–æ—á–Ω–∏–∫ (schema.table.column)": ref,
                "–í –∫–∞–∫–∏—Ö –æ—Ç—á—ë—Ç–∞—Ö –µ—Å—Ç—å (ID)": ", ".join(map(str, used_ids)) if used_ids else "‚Äî",
                "–ù–∞–∑–≤–∞–Ω–∏—è –æ—Ç—á—ë—Ç–æ–≤": ", ".join(used_names) if used_names else "‚Äî",
            })
        df_proto = pd.DataFrame(rows)
        st.dataframe(df_proto, use_container_width=True, height=320)

        # –ë—ã—Å—Ç—Ä–∞—è –æ—Ü–µ–Ω–∫–∞ –ø—Ä–∏–≥–æ–¥–Ω–æ—Å—Ç–∏ –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –Ω–∞–±–æ—Ä–∞
        score, br = feasibility_score(st.session_state.selected_refs, len(st.session_state.selected_refs), allow_vitrine=True)
        c1, c2, c3 = st.columns(3)
        c1.metric("Feasibility", f"{score}/100")
        c2.metric("–°—Ç–∞—Ç—É—Å", status_label(score))
        c3.metric("–ü–æ–ª—è", str(len(st.session_state.selected_refs)))
        st.progress(min(1.0, score/100))
        with st.expander("–î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è –æ—Ü–µ–Ω–∫–∏"):
            st.write(br)

# ------------------------------ TAB 2: –î–ê–ù–ù–´–ï --------------------------------
with tab2:
    c1, c2 = st.columns(2)
    with c1:
        st.write("**–í–∏—Ç—Ä–∏–Ω–∞ (dm.\*)**")
        st.dataframe(datasets.query("layer=='vitrine'")[["name","system","owner","sla_minutes","pii_flags","quality_score","granularity"]]
            .rename(columns={"name":"–ù–∞–±–æ—Ä","system":"–°–∏—Å—Ç–µ–º–∞","owner":"–í–ª–∞–¥–µ–ª–µ—Ü","sla_minutes":"SLA (–º–∏–Ω)","pii_flags":"PII","quality_score":"–ö–∞—á–µ—Å—Ç–≤–æ","granularity":"–ì—Ä–∞–Ω—É–ª—è—Ä–Ω–æ—Å—Ç—å"}),
            use_container_width=True, height=260)
    with c2:
        st.write("**–ò—Å—Ç–æ—á–Ω–∏–∫–∏ (RAW/Source)**")
        st.dataframe(datasets.query("layer!='vitrine'")[["name","system","owner","sla_minutes","pii_flags","quality_score","granularity"]]
            .rename(columns={"name":"–ù–∞–±–æ—Ä","system":"–°–∏—Å—Ç–µ–º–∞","owner":"–í–ª–∞–¥–µ–ª–µ—Ü","sla_minutes":"SLA (–º–∏–Ω)","pii_flags":"PII","quality_score":"–ö–∞—á–µ—Å—Ç–≤–æ","granularity":"–ì—Ä–∞–Ω—É–ª—è—Ä–Ω–æ—Å—Ç—å"}),
            use_container_width=True, height=260)

    st.markdown("### –ü–æ–ª—è")
    st.dataframe(dataset_fields[["schema","table","column","dtype","completeness","uniqueness","tags"]]
        .rename(columns={"schema":"–°—Ö–µ–º–∞","table":"–¢–∞–±–ª–∏—Ü–∞","column":"–ü–æ–ª–µ","dtype":"–¢–∏–ø","completeness":"–ü–æ–ª–Ω–æ—Ç–∞","uniqueness":"–£–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å","tags":"–¢–µ–≥–∏"}),
        use_container_width=True, height=320)

# ------------------------------ TAB 3: –û–¢–ß–Å–¢–´ --------------------------------
with tab3:
    col1, col2, col3, col4 = st.columns(4)
    col1.metric("–í—Å–µ–≥–æ –æ—Ç—á—ë—Ç–æ–≤", len(reports))
    col2.metric("–ê–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–æ", int(reports["is_automated"].sum()))
    col3.metric("–í–∏—Ç—Ä–∏–Ω", datasets.query("layer=='vitrine'").shape[0])
    col4.metric("–ò—Å—Ç–æ—á–Ω–∏–∫–æ–≤", datasets.query("layer!='vitrine'").shape[0])

    st.write("### –ö–∞—Ç–∞–ª–æ–≥ –æ—Ç—á—ë—Ç–æ–≤")
    show = reports.copy()
    st.dataframe(show[["name","owner","business_domain","frequency","is_automated","automation_score","description"]]
        .rename(columns={"name":"–ù–∞–∑–≤–∞–Ω–∏–µ","owner":"–í–ª–∞–¥–µ–ª–µ—Ü","business_domain":"–î–æ–º–µ–Ω","frequency":"–ß–∞—Å—Ç–æ—Ç–∞","is_automated":"–ê–≤—Ç–æ?","automation_score":"–°–∫–æ—Ä","description":"–û–ø–∏—Å–∞–Ω–∏–µ"}),
        use_container_width=True, height=260)

    st.markdown("### –î–µ—Ç–∞–ª–∏")
    selected = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –æ—Ç—á—ë—Ç", options=show["name"].tolist())
    rep = show[show["name"]==selected].iloc[0]
    rid = rep["report_id"]
    cols = st.columns(4)
    cols[0].write(f"**–í–ª–∞–¥–µ–ª–µ—Ü:** {rep['owner']}")
    cols[1].write(f"**–ß–∞—Å—Ç–æ—Ç–∞:** {rep['frequency']}")
    cols[2].write(f"**–°—Ç–∞—Ç—É—Å:** {'–ê–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω' if rep['is_automated'] else '–†—É—á–Ω–æ–π'}")
    cols[3].write(f"**–ì–æ—Ç–æ–≤–Ω–æ—Å—Ç—å:** {status_label(rep['automation_score'])}")
    st.caption(rep["description"])
    rf = report_fields[report_fields["report_id"]==rid]
    st.write("**–ü–æ–ª—è –∏ –∏—Å—Ç–æ—á–Ω–∏–∫–∏:**")
    st.dataframe(rf.rename(columns={
        "business_field_name":"–ë–∏–∑–Ω–µ—Å-–ø–æ–ª–µ","source_ref":"–ò—Å—Ç–æ—á–Ω–∏–∫ (schema.table.column)","is_from_vitrine":"–ò–∑ –≤–∏—Ç—Ä–∏–Ω—ã?"
    }), use_container_width=True, height=220)

# ------------------------------ TAB 4: –ü–†–û–í–ï–†–ö–ê –ü–†–ò–ì–û–î–ù–û–°–¢–ò ------------------
with tab4:
    st.write("–í—Å—Ç–∞–≤—å—Ç–µ —Å–ø–∏—Å–æ–∫ –ø–æ–ª–µ–π (`schema.table.column`) –∏–ª–∏ —Å–æ–±–µ—Ä–∏—Ç–µ –µ–≥–æ –Ω–∞ –≤–∫–ª–∞–¥–∫–µ ¬´–ü–æ–¥–±–æ—Ä –ø–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º¬ª.")
    req = st.text_area("–¢—Ä–µ–±—É–µ–º—ã–µ –ø–æ–ª—è", "\n".join(st.session_state.selected_refs) if st.session_state.selected_refs else "dm.sales_facts.revenue\ndm.sales_dim.channel\ndm.geo_dim.region_name")
    allow_v = st.toggle("–ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤–∏—Ç—Ä–∏–Ω—É", value=True, key="allow_v2")
    if st.button("–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø—Ä–∏–≥–æ–¥–Ω–æ—Å—Ç—å"):
        requested = [x.strip() for x in req.split("\n") if x.strip()]
        known_refs = set(dataset_fields["ref"].tolist())
        found = [r for r in requested if r in known_refs]
        score, br = feasibility_score(found, len(requested), allow_vitrine=allow_v)
        g1, g2, g3 = st.columns(3)
        g1.metric("Feasibility", f"{score}/100")
        g2.metric("–°—Ç–∞—Ç—É—Å", status_label(score))
        g3.metric("–ü–æ–∫—Ä—ã—Ç–∏–µ –ø–æ–ª–µ–π", f"{br.get('–ü–æ–∫—Ä—ã—Ç–∏–µ –ø–æ–ª–µ–π',0)}%")
        st.progress(min(1.0, score/100))
        st.subheader("–î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è")
        st.write(br)
        miss = [r for r in requested if r not in found]
        st.write("**–ù–∞–π–¥–µ–Ω–æ:**", found if found else "‚Äî")
        st.write("**–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç:**", miss if miss else "‚Äî")

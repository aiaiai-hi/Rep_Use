# app.py
import streamlit as st
import pandas as pd
import numpy as np
import math
from collections import defaultdict, Counter

st.set_page_config(page_title="DWH ‚Üí Report Feasibility", layout="wide")

# ------------------------------ TEST DATA -----------------------------------
# Reports
reports = pd.DataFrame([
    {"report_id": 1, "name": "–ü—Ä–æ–¥–∞–∂–∏ –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º", "owner": "BI Team", "frequency": "–ï–∂–µ–¥–Ω–µ–≤–Ω–æ",
     "business_domain": "Sales", "is_automated": True, "automation_score": 92,
     "description": "–í–æ—Ä–æ–Ω–∫–∞ –ø—Ä–æ–¥–∞–∂ –∏ –≤—ã—Ä—É—á–∫–∞ –ø–æ —Ä–µ–≥–∏–æ–Ω–∞–º –∏ –∫–∞–Ω–∞–ª–∞–º."},
    {"report_id": 2, "name": "–ú–∞—Ä–∂–∏–Ω–∞–ª—å–Ω–æ—Å—Ç—å SKU (—Ä—É—á–Ω–æ–π)", "owner": "Finance", "frequency": "–ï–∂–µ–Ω–µ–¥–µ–ª—å–Ω–æ",
     "business_domain": "Finance", "is_automated": False, "automation_score": 58,
     "description": "–†—É—á–Ω–æ–π excel –ø–æ –º–∞—Ä–∂–µ –∏ —Å–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç–∏ –Ω–∞ —É—Ä–æ–≤–Ω–µ SKU."},
    {"report_id": 3, "name": "Churn –¥–∞—à–±–æ—Ä–¥", "owner": "CRM", "frequency": "–ï–∂–µ–º–µ—Å—è—á–Ω–æ",
     "business_domain": "CRM", "is_automated": True, "automation_score": 81,
     "description": "–û—Ç—á—ë—Ç –ø–æ –æ—Ç—Ç–æ–∫—É –∫–ª–∏–µ–Ω—Ç–æ–≤, —Ä–µ—Ç–µ–Ω—à–Ω –∏ —Å–µ–≥–º–µ–Ω—Ç—ã."},
    {"report_id": 4, "name": "–ü–ª–∞–Ω/–§–∞–∫—Ç –î–æ—Ö–æ–¥–æ–≤", "owner": "FP&A", "frequency": "–ï–∂–µ–º–µ—Å—è—á–Ω–æ",
     "business_domain": "Finance", "is_automated": True, "automation_score": 76,
     "description": "–°–≤–æ–¥ –¥–æ—Ö–æ–¥–æ–≤ –ø—Ä–æ—Ç–∏–≤ –±—é–¥–∂–µ—Ç–∞ –ø–æ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è–º."},
])

# Report fields (link business fields to physical refs)
report_fields = pd.DataFrame([
    {"report_id": 1, "business_field_name": "–í—ã—Ä—É—á–∫–∞", "source_ref": "dm.sales_facts.revenue", "is_from_vitrine": True},
    {"report_id": 1, "business_field_name": "–ö–∞–Ω–∞–ª –ø—Ä–æ–¥–∞–∂", "source_ref": "dm.sales_dim.channel", "is_from_vitrine": True},
    {"report_id": 1, "business_field_name": "–†–µ–≥–∏–æ–Ω", "source_ref": "dm.geo_dim.region_name", "is_from_vitrine": True},
    {"report_id": 2, "business_field_name": "SKU", "source_ref": "raw.erp_items.sku", "is_from_vitrine": False},
    {"report_id": 2, "business_field_name": "–°–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å", "source_ref": "raw.erp_costs.cogs", "is_from_vitrine": False},
    {"report_id": 2, "business_field_name": "–¶–µ–Ω–∞ –ø—Ä–æ–¥–∞–∂–∏", "source_ref": "dm.sales_facts.price", "is_from_vitrine": True},
    {"report_id": 3, "business_field_name": "–ö–ª–∏–µ–Ω—Ç", "source_ref": "dm.customer_dim.customer_id", "is_from_vitrine": True},
    {"report_id": 3, "business_field_name": "–°—Ç–∞—Ç—É—Å –æ—Ç—Ç–æ–∫–∞", "source_ref": "dm.customer_facts.churn_flag", "is_from_vitrine": True},
    {"report_id": 3, "business_field_name": "–î–∞—Ç–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–π –ø–æ–∫—É–ø–∫–∏", "source_ref": "dm.customer_facts.last_purchase_dt", "is_from_vitrine": True},
    {"report_id": 4, "business_field_name": "–î–æ—Ö–æ–¥ —Ñ–∞–∫—Ç", "source_ref": "dm.finance_facts.revenue_actual", "is_from_vitrine": True},
    {"report_id": 4, "business_field_name": "–î–æ—Ö–æ–¥ –ø–ª–∞–Ω", "source_ref": "dm.finance_facts.revenue_budget", "is_from_vitrine": True},
])

# Datasets (vitrine & raw)
datasets = pd.DataFrame([
    {"dataset_id": 10, "name": "dm.sales_facts", "layer": "vitrine", "owner": "DWH", "sla_minutes": 120, "pii_flags": "", "quality_score": 0.93, "granularity": "txn_day_sku"},
    {"dataset_id": 11, "name": "dm.customer_facts", "layer": "vitrine", "owner": "DWH", "sla_minutes": 1440, "pii_flags": "PII", "quality_score": 0.88, "granularity": "customer_month"},
    {"dataset_id": 12, "name": "raw.erp_costs", "layer": "raw", "owner": "DataOps", "sla_minutes": 60, "pii_flags": "", "quality_score": 0.76, "granularity": "sku_day"},
    {"dataset_id": 13, "name": "dm.finance_facts", "layer": "vitrine", "owner": "DWH", "sla_minutes": 1440, "pii_flags": "", "quality_score": 0.86, "granularity": "dept_month"},
    {"dataset_id": 14, "name": "raw.crm_events", "layer": "raw", "owner": "MarTech", "sla_minutes": 30, "pii_flags": "PII", "quality_score": 0.71, "granularity": "event"},
    {"dataset_id": 15, "name": "dm.geo_dim", "layer": "vitrine", "owner": "DWH", "sla_minutes": 1440, "pii_flags": "", "quality_score": 0.95, "granularity": "region"},
    {"dataset_id": 16, "name": "dm.sales_dim", "layer": "vitrine", "owner": "DWH", "sla_minutes": 1440, "pii_flags": "", "quality_score": 0.92, "granularity": "channel"},
    {"dataset_id": 17, "name": "dm.customer_dim", "layer": "vitrine", "owner": "DWH", "sla_minutes": 1440, "pii_flags": "PII", "quality_score": 0.90, "granularity": "customer"},
])

# Dataset fields (with simple quality metrics)
dataset_fields = pd.DataFrame([
    # sales_facts
    {"dataset_id": 10, "schema": "dm", "table": "sales_facts", "column": "revenue", "dtype": "decimal", "completeness": 0.99, "uniqueness": 0.95, "tags": ["–≤—ã—Ä—É—á–∫–∞","–¥–æ—Ö–æ–¥","–æ–±–æ—Ä–æ—Ç","revenue","sales"]},
    {"dataset_id": 10, "schema": "dm", "table": "sales_facts", "column": "price", "dtype": "decimal", "completeness": 0.98, "uniqueness": 0.92, "tags": ["—Ü–µ–Ω–∞","price","—Å—Ç–æ–∏–º–æ—Å—Ç—å –ø—Ä–æ–¥–∞–∂–∏"]},
    {"dataset_id": 10, "schema": "dm", "table": "sales_facts", "column": "sku_id", "dtype": "string", "completeness": 0.97, "uniqueness": 0.80, "tags": ["sku","—Ç–æ–≤–∞—Ä","–∞—Ä—Ç–∏–∫—É–ª"]},
    {"dataset_id": 10, "schema": "dm", "table": "sales_facts", "column": "channel", "dtype": "string", "completeness": 0.98, "uniqueness": 0.70, "tags": ["–∫–∞–Ω–∞–ª","–æ–Ω–ª–∞–π–Ω","–æ—Ñ—Ñ–ª–∞–π–Ω","—Ä–æ–∑–Ω–∏—Ü–∞","ecom"]},
    {"dataset_id": 10, "schema": "dm", "table": "sales_facts", "column": "region_id", "dtype": "int", "completeness": 0.98, "uniqueness": 0.60, "tags": ["—Ä–µ–≥–∏–æ–Ω","–≥–µ–æ","–æ–±–ª–∞—Å—Ç—å"]},

    # customer_facts
    {"dataset_id": 11, "schema": "dm", "table": "customer_facts", "column": "churn_flag", "dtype": "bool", "completeness": 0.97, "uniqueness": 1.00, "tags": ["–æ—Ç—Ç–æ–∫","churn","—É—à—ë–ª","—É–¥–µ—Ä–∂–∞–Ω–∏–µ"]},
    {"dataset_id": 11, "schema": "dm", "table": "customer_facts", "column": "last_purchase_dt", "dtype": "date", "completeness": 0.96, "uniqueness": 0.90, "tags": ["–ø–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–∫—É–ø–∫–∞","recency","lrp"]},

    # finance_facts
    {"dataset_id": 13, "schema": "dm", "table": "finance_facts", "column": "revenue_actual", "dtype": "decimal", "completeness": 0.98, "uniqueness": 0.95, "tags": ["–¥–æ—Ö–æ–¥ —Ñ–∞–∫—Ç","—Ñ–∞–∫—Ç","actual","–≤—ã—Ä—É—á–∫–∞"]},
    {"dataset_id": 13, "schema": "dm", "table": "finance_facts", "column": "revenue_budget", "dtype": "decimal", "completeness": 0.98, "uniqueness": 0.95, "tags": ["–ø–ª–∞–Ω –¥–æ—Ö–æ–¥","–±—é–¥–∂–µ—Ç","budget"]},

    # geo_dim
    {"dataset_id": 15, "schema": "dm", "table": "geo_dim", "column": "region_name", "dtype": "string", "completeness": 0.99, "uniqueness": 0.95, "tags": ["—Ä–µ–≥–∏–æ–Ω","–≥–µ–æ–≥—Ä–∞—Ñ–∏—è","—Ä–µ–≥–∏–æ–Ω –Ω–∞–∑–≤–∞–Ω–∏–µ"]},

    # sales_dim
    {"dataset_id": 16, "schema": "dm", "table": "sales_dim", "column": "channel", "dtype": "string", "completeness": 0.99, "uniqueness": 0.95, "tags": ["–∫–∞–Ω–∞–ª","–∫–∞–Ω–∞–ª –ø—Ä–æ–¥–∞–∂","—Ä–æ–∑–Ω–∏—Ü–∞","marketplace"]},

    # customer_dim
    {"dataset_id": 17, "schema": "dm", "table": "customer_dim", "column": "customer_id", "dtype": "string", "completeness": 0.99, "uniqueness": 1.00, "tags": ["–∫–ª–∏–µ–Ω—Ç","customer","–∏–¥ –∫–ª–∏–µ–Ω—Ç–∞"]},

    # raw
    {"dataset_id": 12, "schema": "raw", "table": "erp_costs", "column": "cogs", "dtype": "decimal", "completeness": 0.92, "uniqueness": 0.90, "tags": ["—Å–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å","cogs","–∑–∞—Ç—Ä–∞—Ç—ã"]},
    {"dataset_id": 12, "schema": "raw", "table": "erp_costs", "column": "sku", "dtype": "string", "completeness": 0.94, "uniqueness": 0.80, "tags": ["sku","—Ç–æ–≤–∞—Ä","–∞—Ä—Ç–∏–∫—É–ª"]},

    {"dataset_id": 14, "schema": "raw", "table": "crm_events", "column": "event_type", "dtype": "string", "completeness": 0.91, "uniqueness": 0.65, "tags": ["—Å–æ–±—ã—Ç–∏–µ","email","push","–∫–∞–º–ø–∞–Ω–∏—è"]},
])

# Build ref and reverse indexes
dataset_fields["ref"] = dataset_fields["schema"] + "." + dataset_fields["table"] + "." + dataset_fields["column"]
ref_to_quality = {r["ref"]: (r["completeness"], r["uniqueness"]) for _, r in dataset_fields.iterrows()}
ref_to_layer = {r["ref"]: ("vitrine" if r["schema"]=="dm" else "source") for _, r in dataset_fields.iterrows()}
ref_to_dataset = {r["ref"]: r["dataset_id"] for _, r in dataset_fields.iterrows()}

dataset_id_to_name = {r.dataset_id: r.name for _, r in datasets.iterrows()}
dataset_id_to_layer = {r.dataset_id: r.layer for _, r in datasets.iterrows()}

# Simple business glossary (terms ‚Üí candidate fields/refs)
glossary = [
    {"term": "–≤—ã—Ä—É—á–∫–∞", "syn": ["–¥–æ—Ö–æ–¥","–æ–±–æ—Ä–æ—Ç","revenue","sales"], "refs": ["dm.sales_facts.revenue","dm.finance_facts.revenue_actual","dm.finance_facts.revenue_budget"]},
    {"term": "–º–∞—Ä–∂–∞", "syn": ["–ø—Ä–∏–±—ã–ª—å","margin"], "refs": ["dm.sales_facts.price","raw.erp_costs.cogs"]},
    {"term": "—Å–µ–±–µ—Å—Ç–æ–∏–º–æ—Å—Ç—å", "syn": ["cogs","–∑–∞—Ç—Ä–∞—Ç—ã"], "refs": ["raw.erp_costs.cogs"]},
    {"term": "–∫–∞–Ω–∞–ª –ø—Ä–æ–¥–∞–∂", "syn": ["–∫–∞–Ω–∞–ª","—Ä–æ–∑–Ω–∏—Ü–∞","–æ–Ω–ª–∞–π–Ω","marketplace","ecom"], "refs": ["dm.sales_facts.channel","dm.sales_dim.channel"]},
    {"term": "—Ä–µ–≥–∏–æ–Ω", "syn": ["–≥–µ–æ","–æ–±–ª–∞—Å—Ç—å","—Ä–µ–≥–∏–æ–Ω –Ω–∞–∑–≤–∞–Ω–∏–µ"], "refs": ["dm.geo_dim.region_name","dm.sales_facts.region_id"]},
    {"term": "–∫–ª–∏–µ–Ω—Ç", "syn": ["customer","–∏–¥ –∫–ª–∏–µ–Ω—Ç–∞"], "refs": ["dm.customer_dim.customer_id"]},
    {"term": "–æ—Ç—Ç–æ–∫", "syn": ["churn","—É—à—ë–ª","retention"], "refs": ["dm.customer_facts.churn_flag"]},
    {"term": "–ø–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–∫—É–ø–∫–∞", "syn": ["recency","lrp"], "refs": ["dm.customer_facts.last_purchase_dt"]},
    {"term": "sku", "syn": ["—Ç–æ–≤–∞—Ä","–∞—Ä—Ç–∏–∫—É–ª","–ø–æ–∑–∏—Ü–∏—è"], "refs": ["dm.sales_facts.sku_id","raw.erp_costs.sku"]},
    {"term": "–ø–ª–∞–Ω –¥–æ—Ö–æ–¥–∞", "syn": ["–±—é–¥–∂–µ—Ç","budget"], "refs": ["dm.finance_facts.revenue_budget"]},
]

stop_words = set("–∏ –∏–ª–∏ –≤ –Ω–∞ –ø–æ –∑–∞ –æ—Ç –¥–æ –ø—Ä–∏ –∫–∞–∫ –¥–ª—è –∫ –∏–∑ —É –∂–µ –∂–µ-—Ç–æ –æ –æ–± –æ–±–æ –ø—Ä–æ –Ω–∞–¥ –ø–æ–¥ –º–µ–∂–¥—É –±–µ–∑ –æ–∫–æ–ª–æ –ø—Ä–æ".split())

# --------------------------- UTILS / LOGIC -----------------------------------
def normalize(q: str) -> list:
    q = (q or "").lower()
    tokens = []
    for t in q.replace(",", " ").replace(".", " ").replace("/", " ").replace("-", " ").split():
        if t and t not in stop_words:
            tokens.append(t)
    return tokens

def jaccard(a:set, b:set)->float:
    if not a or not b: return 0.0
    return len(a & b) / len(a | b)

def match_glossary(query: str, top_k: int = 8):
    tokens = set(normalize(query))
    candidates = []
    for g in glossary:
        keyset = set([g["term"]] + g["syn"])
        score = jaccard(tokens, set(normalize(" ".join(list(keyset)))))
        if score>0:
            candidates.append({"term": g["term"], "score": score, "refs": g["refs"]})
    candidates.sort(key=lambda x: x["score"], reverse=True)
    # Expand to field suggestions
    ref_scores = defaultdict(float)
    for c in candidates:
        for r in c["refs"]:
            ref_scores[r] = max(ref_scores[r], c["score"])
    # tag-based soft match across dataset_fields
    for _, row in dataset_fields.iterrows():
        tagset = set(normalize(" ".join(row["tags"])))
        s = jaccard(tokens, tagset)
        if s>0:
            ref_scores[row["ref"]] = max(ref_scores[row["ref"]], s*0.9)  # a bit lower than glossary
    ranked = sorted(ref_scores.items(), key=lambda x: x[1], reverse=True)[:top_k]
    return ranked  # list of (ref, score)

def feasibility_score(found_refs, total_refs, allow_vitrine=True):
    if total_refs == 0: 
        return 0, {}
    coverage = len(found_refs) / total_refs
    freshness = 0.8 if allow_vitrine else 0.9
    if found_refs:
        qualities = [ref_to_quality.get(r, (0.7,0.7))[0] for r in found_refs]
        quality = float(np.mean(qualities))
    else:
        quality = 0.5
    access = 0.9
    if found_refs:
        in_vitrine = [r for r in found_refs if ref_to_layer.get(r)=="vitrine"]
        reuse = 1.0 if len(in_vitrine) / len(found_refs) >= 0.7 else 0.4
    else:
        reuse = 0.3
    score = (
        coverage * 0.40 +
        freshness * 0.20 +
        quality * 0.15 +
        access * 0.15 +
        reuse * 0.10
    ) * 100
    breakdown = {
        "–ü–æ–∫—Ä—ã—Ç–∏–µ –ø–æ–ª–µ–π": round(coverage*100),
        "–°–≤–µ–∂–µ—Å—Ç—å/SLA": round(freshness*100),
        "–ö–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö": round(quality*100),
        "–î–æ—Å—Ç—É–ø": round(access*100),
        "–ü–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ": round(reuse*100),
    }
    return round(score), breakdown

def status_label(score):
    if score >= 85: return "‚úÖ –ì–æ—Ç–æ–≤–æ"
    if score >= 60: return "üü° –ß–∞—Å—Ç–∏—á–Ω–æ"
    return "üî¥ –¢—Ä–µ–±—É–µ—Ç—Å—è –¥–æ—Ä–∞–±–æ—Ç–∫–∞"

def graphviz_lineage(refs:list):
    import graphviz as gv
    dot = gv.Digraph(format="svg")
    dot.attr(rankdir="LR")
    # Draw nodes for datasets and fields
    seen_ds = set()
    for r in refs:
        ds_id = ref_to_dataset.get(r)
        ds_name = dataset_id_to_name.get(ds_id, "dataset")
        layer = dataset_id_to_layer.get(ds_id, "source")
        ds_label = f"{ds_name}\n({layer})"
        if ds_id not in seen_ds:
            dot.node(f"ds_{ds_id}", ds_label, shape="folder" if layer=="vitrine" else "box3d")
            seen_ds.add(ds_id)
        dot.node(f"f_{r}", r.split(".")[-1], shape="note")
        dot.edge(f"ds_{ds_id}", f"f_{r}")
    # Simple pipeline chain demo
    for r in refs:
        if r.startswith("raw."):
            # show transform to dm.* if similarly named exists
            raw_tail = r.split(".",2)[-1]
            for r2 in refs:
                if r2.startswith("dm.") and r2.endswith(raw_tail.split(".")[-1]):
                    dot.edge(f"f_{r}", f"f_{r2}", label="transform")
    return dot

# ------------------------------ SIDEBAR --------------------------------------
st.sidebar.header("–ì–ª–æ–±–∞–ª—å–Ω—ã–π –ø–æ–∏—Å–∫")
q = st.sidebar.text_input("–ù–∞–ø—Ä–∏–º–µ—Ä: ¬´—Ö–æ—á—É —Å—Ä–∞–≤–Ω–∏—Ç—å –≤—ã—Ä—É—á–∫—É –∏ –º–∞—Ä–∂—É –ø–æ –∫–∞–Ω–∞–ª–∞–º –∏ —Ä–µ–≥–∏–æ–Ω–∞–º –∑–∞ –º–µ—Å—è—Ü¬ª")
allow_vitrine = st.sidebar.toggle("–†–∞–∑—Ä–µ—à–∏—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤–∏—Ç—Ä–∏–Ω—É", value=True)
if st.sidebar.button("–ü–æ–¥–æ–±—Ä–∞—Ç—å –ø–æ–ª—è"):
    ranked = match_glossary(q, top_k=10)
    st.sidebar.write("–ü–æ–¥—Ö–æ–¥—è—â–∏–µ –ø–æ–ª—è:")
    for ref, sc in ranked:
        layer = ref_to_layer.get(ref, "?")
        st.sidebar.write(f"- {ref}  ¬∑ {layer}  ¬∑ score={sc:.2f}")

st.sidebar.markdown("---")
st.sidebar.header("–ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ (–ø–æ —Å–ø–∏—Å–∫—É –ø–æ–ª–µ–π)")
raw_req = st.sidebar.text_area("–°–ø–∏—Å–æ–∫ `schema.table.column` (–ø–æ –æ–¥–Ω–æ–º—É –Ω–∞ —Å—Ç—Ä–æ–∫–µ)", "dm.sales_facts.revenue\ndm.sales_dim.channel\ndm.geo_dim.region_name\nraw.erp_costs.cogs")
if st.sidebar.button("–û—Ü–µ–Ω–∏—Ç—å –ø—Ä–∏–≥–æ–¥–Ω–æ—Å—Ç—å"):
    requested = [x.strip() for x in raw_req.splitlines() if x.strip()]
    known = set(dataset_fields["ref"].tolist())
    found = [r for r in requested if r in known]
    score, br = feasibility_score(found, len(requested), allow_vitrine=allow_vitrine)
    st.sidebar.metric("Feasibility", f"{score}/100")
    st.sidebar.write(status_label(score))
    st.sidebar.write("–ù–∞–π–¥–µ–Ω–æ:", found if found else "‚Äî")
    miss = [r for r in requested if r not in found]
    st.sidebar.write("–ù–µ—Ç –≤ –∫–∞—Ç–∞–ª–æ–≥–µ:", miss if miss else "‚Äî")

# ------------------------------ HEADER ---------------------------------------
st.title("–ö–∞—Ç–∞–ª–æ–≥ –¥–∞–Ω–Ω—ã—Ö –∏ –æ—Ç—á—ë—Ç–æ–≤ ‚Üí –ü–æ–¥–±–æ—Ä –ø–æ —Ö–æ—Ç–µ–ª–∫–∞–º –∏ –ø—Ä–æ–≤–µ—Ä–∫–∞ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏")
st.caption("–û–ø—Ä–µ–¥–µ–ª–∏: –º–æ–∂–Ω–æ –ª–∏ —Å–æ–±—Ä–∞—Ç—å –Ω–æ–≤—ã–π –æ—Ç—á—ë—Ç –∏–∑ —Ç–µ–∫—É—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∏ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ä—É—á–Ω–æ–π.")

tab1, tab2, tab3, tab4 = st.tabs(["üîé –ü–æ–¥–±–æ—Ä –ø–æ —Ö–æ—Ç–µ–ª–∫–µ", "üìä –û—Ç—á—ë—Ç—ã", "üß± –î–∞–Ω–Ω—ã–µ", "üß™ –ö–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä –ø—Ä–æ–≤–µ—Ä–∫–∏"])

# ------------------------------ TAB 1: WIZARD --------------------------------
with tab1:
    st.subheader("–û–ø–∏—à–∏, —á—Ç–æ —Ö–æ—á–µ—à—å —É–≤–∏–¥–µ—Ç—å")
    example = "–ù—É–∂–Ω–∞ –¥–∏–Ω–∞–º–∏–∫–∞ –≤—ã—Ä—É—á–∫–∏ –∏ –º–∞—Ä–∂–∏ –ø–æ –∫–∞–Ω–∞–ª–∞–º –ø—Ä–æ–¥–∞–∂ –∏ —Ä–µ–≥–∏–æ–Ω–∞–º –∑–∞ –∫–≤–∞—Ä—Ç–∞–ª."
    want = st.text_area("–°–≤–æ–±–æ–¥–Ω—ã–π –≤–≤–æ–¥ (–µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–π —è–∑—ã–∫)", value=example, height=90)
    gran = st.selectbox("–ñ–µ–ª–∞–µ–º–∞—è –ø–µ—Ä–∏–æ–¥–∏—á–Ω–æ—Å—Ç—å", ["–¥–µ–Ω—å","–Ω–µ–¥–µ–ª—è","–º–µ—Å—è—Ü","–∫–≤–∞—Ä—Ç–∞–ª"], index=2)
    level = st.multiselect("–ì—Ä–∞–Ω—É–ª—è—Ä–Ω–æ—Å—Ç—å (–∏–∑–º–µ—Ä–µ–Ω–∏—è)", ["—Ä–µ–≥–∏–æ–Ω","–∫–∞–Ω–∞–ª –ø—Ä–æ–¥–∞–∂","SKU","–∫–ª–∏–µ–Ω—Ç"], default=["—Ä–µ–≥–∏–æ–Ω","–∫–∞–Ω–∞–ª –ø—Ä–æ–¥–∞–∂"])
    if st.button("–ü–æ–¥–æ–±—Ä–∞—Ç—å –¥–∞–Ω–Ω—ã–µ"):
        ranked = match_glossary(want, top_k=12)
        if not ranked:
            st.warning("–ù–µ –Ω–∞—à–ª–∞ —è–≤–Ω—ã—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π. –ü–æ–ø—Ä–æ–±—É–π –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –∑–∞–ø—Ä–æ—Å –±–æ–ª–µ–µ –ø—Ä–µ–¥–º–µ—Ç–Ω–æ (–≤—ã—Ä—É—á–∫–∞/–∫–ª–∏–µ–Ω—Ç/–∫–∞–Ω–∞–ª/—Ä–µ–≥–∏–æ–Ω).")
        else:
            # Build suggestion table
            rows = []
            for ref, sc in ranked:
                ds_id = ref_to_dataset.get(ref)
                ds = datasets[datasets.dataset_id==ds_id].iloc[0]
                rows.append({
                    "–ü–æ–ª–µ": ref.split(".")[-1],
                    "–ò—Å—Ç–æ—á–Ω–∏–∫": ref,
                    "–ù–∞–±–æ—Ä": ds.name,
                    "–°–ª–æ–π": ds.layer,
                    "SLA (–º–∏–Ω)": ds.sla_minutes,
                    "PII": ds.pii_flags or "‚Äî",
                    "–ö–∞—á–µ—Å—Ç–≤–æ –Ω–∞–±–æ—Ä–∞": ds.quality_score,
                    "Score": round(sc, 2)
                })
            st.write("**–ö–∞–Ω–¥–∏–¥–∞—Ç—ã –ø–æ–ª–µ–π –ø–æ–¥ –≤–∞—à—É —Ö–æ—Ç–µ–ª–∫—É:**")
            st.dataframe(pd.DataFrame(rows), use_container_width=True)

            # Choose top 5 distinct by semantic diversity (by dataset preference to vitrine)
            picked = []
            seen_cols = set()
            for ref, sc in ranked:
                col = ref.split(".")[-1]
                if col in seen_cols: 
                    continue
                seen_cols.add(col)
                picked.append(ref)
                if len(picked)>=5: break

            st.markdown("### –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–Ω—ã–π –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –Ω–∞–±–æ—Ä –ø–æ–ª–µ–π")
            st.code("\n".join(picked))

            # Feasibility using picked
            score, br = feasibility_score(picked, len(picked), allow_vitrine=True)
            c1, c2, c3 = st.columns(3)
            c1.metric("Feasibility", f"{score}/100")
            c2.metric("–°—Ç–∞—Ç—É—Å", status_label(score))
            c3.metric("–ü–æ–∫—Ä—ã—Ç–∏–µ –ø–æ–ª–µ–π", f"{br.get('–ü–æ–∫—Ä—ã—Ç–∏–µ –ø–æ–ª–µ–π',0)}%")
            st.progress(min(1.0, score/100))
            with st.expander("–î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è –æ—Ü–µ–Ω–∫–∏"):
                st.write(br)

            # Reuse suggestions: existing automated reports overlapping
            st.markdown("### –ü–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –æ—Ç—á—ë—Ç–æ–≤/–≤–∏—Ç—Ä–∏–Ω—ã")
            # overlap with reports
            rep_overlap = []
            for rid, group in report_fields.groupby("report_id"):
                fields = set(group["source_ref"].tolist())
                inter = set(picked) & fields
                if inter:
                    ratio = len(inter)/len(picked)
                    rep = reports[reports.report_id==rid].iloc[0]
                    rep_overlap.append({
                        "–û—Ç—á—ë—Ç": rep["name"],
                        "–ê–≤—Ç–æ?": "–î–∞" if rep["is_automated"] else "–ù–µ—Ç",
                        "–°–æ–≤–ø–∞–¥–µ–Ω–∏–µ": f"{int(ratio*100)}%",
                        "–°–æ–≤–ø–∞–≤—à–∏–µ –ø–æ–ª—è": ", ".join([r.split(".")[-1] for r in inter])
                    })
            if rep_overlap:
                st.dataframe(pd.DataFrame(rep_overlap), use_container_width=True)
            else:
                st.info("–ü—Ä—è–º–æ–≥–æ –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –æ—Ç—á—ë—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ. –°–æ—Å—Ä–µ–¥–æ—Ç–æ—á—å—Å—è –Ω–∞ –≤–∏—Ç—Ä–∏–Ω–µ –∏ –¥–∞—Ç–∞—Å–µ—Ç–∞—Ö –Ω–∏–∂–µ.")

            # Reuse via vitrine share
            vit_share = sum(1 for r in picked if ref_to_layer.get(r)=="vitrine")/max(1,len(picked))
            if vit_share >= 0.7:
                st.success("‚â•70% –ø–æ–ª–µ–π –¥–æ—Å—Ç—É–ø–Ω—ã –≤ –≤–∏—Ç—Ä–∏–Ω–µ (dm.*) ‚Äî —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –µ—ë –Ω–∞–ø—Ä—è–º—É—é.")
            else:
                st.info("–°—É—â–µ—Å—Ç–≤–µ–Ω–Ω–∞—è —á–∞—Å—Ç—å –ø–æ–ª–µ–π –≤ RAW ‚Äî –ø–æ—Ç—Ä–µ–±—É–µ—Ç—Å—è –ø–∞–π–ø–ª–∞–π–Ω –≤ –≤–∏—Ç—Ä–∏–Ω—É/–¥–∞—Ç–∞–º–∞—Ä—Ç.")

            # Lineage graph
            st.markdown("### –õ–∏–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö (—á–µ—Ä–Ω–æ–≤–∏–∫)")
            try:
                dot = graphviz_lineage(picked)
                st.graphviz_chart(dot)
            except Exception as e:
                st.caption(f"–ì—Ä–∞—Ñ–≤–∏–∑ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")

            # Action plan
            st.markdown("### –ü–ª–∞–Ω –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ (—á–µ—Ä–Ω–æ–≤–∏–∫)")
            steps = []
            if vit_share < 0.7:
                steps.append("–í—ã–Ω–µ—Å—Ç–∏ —Ä–∞—Å—á—ë—Ç—ã –∏ –∫–ª—é—á–µ–≤—ã–µ –ø–æ–ª—è –≤ –≤–∏—Ç—Ä–∏–Ω—É (dm.*), –≤—ã—Ä–æ–≤–Ω—è—Ç—å –≥—Ä–∞–Ω—É–ª—è—Ä–Ω–æ—Å—Ç—å –ø–æ–¥ —Ç—Ä–µ–±—É–µ–º—É—é –ø–µ—Ä–∏–æ–¥–∏—á–Ω–æ—Å—Ç—å.")
            if "–∫–ª–∏–µ–Ω—Ç" in level and any("PII" in (datasets[datasets.dataset_id==ref_to_dataset[r]].iloc[0].pii_flags or "") for r in picked):
                steps.append("–ü—Ä–æ–≤–µ—Ä–∏—Ç—å PII/–¥–æ—Å—Ç—É–ø—ã –¥–ª—è –∫–ª–∏–µ–Ω—Ç—Å–∫–∏—Ö –ø–æ–ª–µ–π, –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å –º–∞—Å–∫–∏ –∏ —Ä–æ–ª–∏.")
            steps.append("–°—Ä–∞–≤–Ω–∏—Ç—å SLA –Ω–∞–±–æ—Ä–∞ —Å —Ç—Ä–µ–±—É–µ–º–æ–π —á–∞—Å—Ç–æ—Ç–æ–π –∏ –æ–±–Ω–æ–≤–∏—Ç—å —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ.")
            steps.append("–ó–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞—Ç—å –±–∏–∑–Ω–µ—Å-—Ç–µ—Ä–º–∏–Ω—ã –≤ –≥–ª–æ—Å—Å–∞—Ä–∏–∏ (–≤—ã—Ä—É—á–∫–∞/–º–∞—Ä–∂–∞/–∫–∞–Ω–∞–ª/—Ä–µ–≥–∏–æ–Ω).")
            for i,s in enumerate(steps,1):
                st.write(f"{i}. {s}")

# ------------------------------ TAB 2: REPORTS -------------------------------
with tab2:
    col1, col2, col3, col4 = st.columns(4)
    col1.metric("–í—Å–µ–≥–æ –æ—Ç—á—ë—Ç–æ–≤", len(reports))
    col2.metric("–ê–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–æ", int(reports["is_automated"].sum()))
    col3.metric("–í–∏—Ç—Ä–∏–Ω", datasets.query("layer=='vitrine'").shape[0])
    col4.metric("–ò—Å—Ç–æ—á–Ω–∏–∫–æ–≤", datasets.query("layer!='vitrine'").shape[0])

    st.write("### –ö–∞—Ç–∞–ª–æ–≥ –æ—Ç—á—ë—Ç–æ–≤")
    show = reports.copy()
    st.dataframe(show[["name","owner","business_domain","frequency","is_automated","automation_score","description"]]
                 .rename(columns={"name":"–ù–∞–∑–≤–∞–Ω–∏–µ","owner":"–í–ª–∞–¥–µ–ª–µ—Ü","business_domain":"–î–æ–º–µ–Ω",
                                  "frequency":"–ß–∞—Å—Ç–æ—Ç–∞","is_automated":"–ê–≤—Ç–æ?","automation_score":"–°–∫–æ—Ä","description":"–û–ø–∏—Å–∞–Ω–∏–µ"}),
                 use_container_width=True, height=240)

    st.markdown("### –î–µ—Ç–∞–ª–∏")
    selected = st.selectbox("–í—ã–±–µ—Ä–∏ –æ—Ç—á—ë—Ç", options=show["name"].tolist())
    rep = show[show["name"]==selected].iloc[0]
    rid = rep["report_id"]
    cols = st.columns(4)
    cols[0].write(f"**–í–ª–∞–¥–µ–ª–µ—Ü:** {rep['owner']}")
    cols[1].write(f"**–ß–∞—Å—Ç–æ—Ç–∞:** {rep['frequency']}")
    cols[2].write(f"**–°—Ç–∞—Ç—É—Å:** {'–ê–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω' if rep['is_automated'] else '–†—É—á–Ω–æ–π'}")
    cols[3].write(f"**–ì–æ—Ç–æ–≤–Ω–æ—Å—Ç—å:** {status_label(rep['automation_score'])}")
    st.caption(rep["description"])

    rf = report_fields[report_fields["report_id"]==rid]
    st.write("**–ü–æ–ª—è –∏ –∏—Å—Ç–æ—á–Ω–∏–∫–∏:**")
    st.dataframe(rf.rename(columns={
        "business_field_name":"–ë–∏–∑–Ω–µ—Å-–ø–æ–ª–µ","source_ref":"–ò—Å—Ç–æ—á–Ω–∏–∫ (schema.table.column)","is_from_vitrine":"–ò–∑ –≤–∏—Ç—Ä–∏–Ω—ã?"
    }), use_container_width=True, height=220)

    with st.expander("–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é"):
        in_vitrine_share = (rf["is_from_vitrine"].mean() if not rf.empty else 0)
        if in_vitrine_share >= 0.7:
            st.success("‚â•70% –ø–æ–ª–µ–π –∏–∑ –≤–∏—Ç—Ä–∏–Ω—ã ‚Äî –≤—ã—Å–æ–∫–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –±—ã—Å—Ç—Ä–æ–≥–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è/–ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è.")
        else:
            st.info("–ó–∞–º–µ—Ç–Ω–∞—è –¥–æ–ª—è –ø–æ–ª–µ–π –∏–∑ RAW ‚Äî —Å—Ç–æ–∏—Ç –≤—ã–Ω–µ—Å—Ç–∏ –∏—Ö –≤ –¥–∞—Ç–∞–º–∞—Ä—Ç –∏ —Å—Ç–∞–±–∏–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ä–∞—Å—á—ë—Ç—ã.")

# ------------------------------ TAB 3: DATA ----------------------------------
with tab3:
    c1, c2 = st.columns(2)
    with c1:
        st.write("**–í–∏—Ç—Ä–∏–Ω–∞ (dm.*)**")
        st.dataframe(datasets.query("layer=='vitrine'")[["name","owner","sla_minutes","pii_flags","quality_score","granularity"]]
                     .rename(columns={"name":"–ù–∞–±–æ—Ä","owner":"–í–ª–∞–¥–µ–ª–µ—Ü","sla_minutes":"SLA (–º–∏–Ω)","pii_flags":"PII","quality_score":"–ö–∞—á–µ—Å—Ç–≤–æ","granularity":"–ì—Ä–∞–Ω—É–ª—è—Ä–Ω–æ—Å—Ç—å"}),
                     use_container_width=True, height=240)
    with c2:
        st.write("**–ò—Å—Ç–æ—á–Ω–∏–∫–∏ (RAW/Source)**")
        st.dataframe(datasets.query("layer!='vitrine'")[["name","owner","sla_minutes","pii_flags","quality_score","granularity"]]
                     .rename(columns={"name":"–ù–∞–±–æ—Ä","owner":"–í–ª–∞–¥–µ–ª–µ—Ü","sla_minutes":"SLA (–º–∏–Ω)","pii_flags":"PII","quality_score":"–ö–∞—á–µ—Å—Ç–≤–æ","granularity":"–ì—Ä–∞–Ω—É–ª—è—Ä–Ω–æ—Å—Ç—å"}),
                     use_container_width=True, height=240)
    st.markdown("### –ü–æ–ª—è")
    st.dataframe(dataset_fields[["schema","table","column","dtype","completeness","uniqueness","tags"]]
                 .rename(columns={"schema":"–°—Ö–µ–º–∞","table":"–¢–∞–±–ª–∏—Ü–∞","column":"–ü–æ–ª–µ","dtype":"–¢–∏–ø","completeness":"–ü–æ–ª–Ω–æ—Ç–∞","uniqueness":"–£–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å","tags":"–¢–µ–≥–∏"}),
                 use_container_width=True, height=300)

# ------------------------------ TAB 4: FEASIBILITY ---------------------------
with tab4:
    st.write("–í—Å—Ç–∞–≤—å —Å–ø–∏—Å–æ–∫ –ø–æ–ª–µ–π (`schema.table.column`) –∏–ª–∏ —Å–æ–±–µ—Ä–∏ –∏–∑ –∫–∞—Ç–∞–ª–æ–≥–∞.")
    req = st.text_area("–¢—Ä–µ–±—É–µ–º—ã–µ –ø–æ–ª—è", "dm.sales_facts.revenue\ndm.sales_dim.channel\ndm.geo_dim.region_name\ndm.customer_facts.churn_flag")
    allow_v = st.toggle("–ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤–∏—Ç—Ä–∏–Ω—É", value=True, key="allow_v2")
    if st.button("–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø—Ä–∏–≥–æ–¥–Ω–æ—Å—Ç—å"):
        requested = [x.strip() for x in req.split("\n") if x.strip()]
        known_refs = set(dataset_fields["ref"].tolist())
        found = [r for r in requested if r in known_refs]
        score, br = feasibility_score(found, len(requested), allow_vitrine=allow_v)
        g1, g2, g3 = st.columns(3)
        g1.metric("Feasibility", f"{score}/100")
        g2.metric("–°—Ç–∞—Ç—É—Å", status_label(score))
        g3.metric("–ü–æ–∫—Ä—ã—Ç–∏–µ –ø–æ–ª–µ–π", f"{br.get('–ü–æ–∫—Ä—ã—Ç–∏–µ –ø–æ–ª–µ–π',0)}%")
        st.progress(min(1.0, score/100))
        st.subheader("–î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è")
        st.write(br)
        miss = [r for r in requested if r not in found]
        st.write("**–ù–∞–π–¥–µ–Ω–æ:**", found if found else "‚Äî")
        st.write("**–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç:**", miss if miss else "‚Äî")
        if found:
            vit_share = sum(1 for r in found if ref_to_layer.get(r)=="vitrine")/len(found)
            if vit_share >= 0.7:
                st.success("–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤–∏—Ç—Ä–∏–Ω—É: ‚â•70% –ø–æ–ª–µ–π –¥–æ—Å—Ç—É–ø–Ω—ã –≤ `dm.*`.")
            else:
                st.info("–ß–∞—Å—Ç—å –ø–æ–ª–µ–π —Ç–æ–ª—å–∫–æ –≤ –∏—Å—Ç–æ—á–Ω–∏–∫–∞—Ö ‚Äî –¥–æ–±–∞–≤—å—Ç–µ –∏—Ö –≤ –¥–∞—Ç–∞–º–∞—Ä—Ç/–≤–∏—Ç—Ä–∏–Ω—É.")
        st.markdown("#### –ü–ª–∞–Ω –¥–µ–π—Å—Ç–≤–∏–π (—á–µ—Ä–Ω–æ–≤–∏–∫)")
        steps = []
        if miss:
            steps.append("–î–æ–±–∞–≤–∏—Ç—å –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –ø–æ–ª—è –≤ –ø–∞–π–ø–ª–∞–π–Ω (RAW ‚Üí CLEAN ‚Üí –í–∏—Ç—Ä–∏–Ω–∞), –æ–ø–∏—Å–∞—Ç—å —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏.")
        if found:
            vit_share = sum(1 for r in found if ref_to_layer.get(r)=="vitrine")/len(found)
            if vit_share < 0.7:
                steps.append("–£–∫—Ä–µ–ø–∏—Ç—å –≤–∏—Ç—Ä–∏–Ω—É: –≤—ã–Ω–µ—Å—Ç–∏ —Ä–∞—Å—á—ë—Ç—ã –≤ –¥–∞—Ç–∞–º–∞—Ä—Ç, –≤—ã—Ä–æ–≤–Ω—è—Ç—å –≥—Ä–∞–Ω—É–ª—è—Ä–Ω–æ—Å—Ç—å.")
        steps.append("–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –¥–æ—Å—Ç—É–ø—ã –∏ —Ñ–ª–∞–≥–∏ PII, —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞—Ç—å SLA —Å —Ç—Ä–µ–±—É–µ–º–æ–π —á–∞—Å—Ç–æ—Ç–æ–π.")
        for i, s in enumerate(steps, 1):
            st.write(f"{i}. {s}")
